{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepNet-Simple.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GunTNwzVQaW"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "eval_data_original = np.load(\"/content/drive/MyDrive/Colab Notebooks/eval_data_complete.npy\")\n",
        "eval_label_original = np.load(\"/content/drive/MyDrive/Colab Notebooks/eval_label_complete.npy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wN4o-lEJV_rp"
      },
      "source": [
        "eval_data = eval_data_original[10:-50]\n",
        "eval_label = eval_label_original[10:-50]\n",
        "\n",
        "test_data = np.concatenate((eval_data_original[:10], eval_data_original[-50:]))\n",
        "test_label = np.concatenate((eval_label_original[:10], eval_label_original[-50:]))\n",
        "\n",
        "eval_data_original = 0\n",
        "eval_label_original = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxotT5rwWs_C",
        "outputId": "1ca46b81-2710-41e2-d18c-469f01c77fba"
      },
      "source": [
        "eval_data = np.concatenate((eval_data[:337], eval_data[:337], eval_data[:337], eval_data[:337], eval_data))\n",
        "eval_label = np.concatenate((eval_label[:337], eval_label[:337], eval_label[:337], eval_label[:337], eval_label))\n",
        "print(eval_data.shape)\n",
        "print(eval_label.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3483, 22, 15000)\n",
            "(3483,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnCVO4zuW24_"
      },
      "source": [
        "idx = np.random.permutation(len(eval_data))\n",
        "eval_data,eval_label = eval_data[idx], eval_label[idx]\n",
        "idx = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "211iSlfRW7X_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af25f5c6-5768-4db6-f232-e3442aa18e27"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "enc_labels = to_categorical(eval_label, num_classes=2)              \n",
        "test_label = to_categorical(test_label, num_classes=2)     \n",
        "eval_label= enc_labels\n",
        "enc_labels = 0\n",
        "print(eval_data.shape)\n",
        "print(eval_label.shape)\n",
        "print(eval_data.dtype)\n",
        "print(eval_label.dtype)\n",
        "print('training labels have been loaded')\n",
        "\n",
        "bs,t,f = eval_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3483, 22, 15000)\n",
            "(3483, 2)\n",
            "float32\n",
            "float32\n",
            "training labels have been loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wom8L3euXITh",
        "outputId": "5357fdff-78d6-464f-a7d0-9545a3f19028"
      },
      "source": [
        "from pdb import set_trace\n",
        "#import mne\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import os\n",
        "import h5py\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN,LSTM, Dense, Activation, Bidirectional\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Convolution2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import MaxPooling1D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import MaxPooling3D\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "# ----------------------DEEP-NET Testing-----------------------\n",
        "from tensorflow.keras.layers import Input,Dense,concatenate,Flatten,GRU,Conv1D,Conv2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "inputsin= Input(shape=(t,f))\n",
        "\n",
        "\n",
        "# ------------------First Inception\n",
        "deep_net = Conv1D(25, 10, strides=1, activation='relu',padding=\"causal\")(inputsin)\n",
        "deep_net = MaxPooling1D(3, 3, padding=\"same\")(deep_net)\n",
        "\n",
        "deep_net = Conv1D(50, 10, activation='relu', padding='causal')(deep_net)\n",
        "deep_net = MaxPooling1D(3, 3, padding='same')(deep_net)\n",
        "\n",
        "deep_net = Conv1D(100, 10, activation='relu', padding='causal')(deep_net)\n",
        "deep_net = MaxPooling1D(3, 3, padding='same')(deep_net)\n",
        "\n",
        "deep_net = Conv1D(200, 10, activation='relu', padding='causal')(deep_net)\n",
        "deep_net = MaxPooling1D(3, 3, padding='same')(deep_net)\n",
        "\n",
        "deep_net = Flatten()(deep_net)\n",
        "predictions = Dense(2,activation='softmax')(deep_net)\n",
        "\n",
        "\n",
        "deep_model = Model(inputs=inputsin, outputs=predictions)\n",
        "\n",
        "# learning rate to 0.00001\n",
        "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
        "\n",
        "deep_model.compile(optimizer = adam_optimizer, loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "print(deep_model.metrics_names)\n",
        "print(deep_model.summary())\n",
        "\n",
        "# early stopping\n",
        "es = EarlyStopping(monitor='val_loss', min_delta=0.01, mode='min', verbose=1, patience=25)                                # patience\n",
        "mc = ModelCheckpoint('deep_model3flipped_acc.hdf5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)        # filepath (save model as)\n",
        "mces = ModelCheckpoint('deep_model3flipped_loss.hdf5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)    # filepath (save model as)\n",
        "\n",
        "# fit model\n",
        "# hist=deep_model.fit(eval_data,eval_label,validation_split=0.1, epochs=20,batch_size=64,verbose=1,callbacks=[es, mc,mces],shuffle=False) #epochs #split #\n",
        "\n",
        "\n",
        "\n",
        "print('The End')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 22, 15000)]       0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 22, 25)            3750025   \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 8, 25)             0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 8, 50)             12550     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 3, 50)             0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 3, 100)            50100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 1, 100)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1, 200)            200200    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 1, 200)            0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 402       \n",
            "=================================================================\n",
            "Total params: 4,013,277\n",
            "Trainable params: 4,013,277\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "The End\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYqRHbgvi9Ae",
        "outputId": "c2835a24-9211-4196-ba22-cbc2b10f1cd5"
      },
      "source": [
        "hist=deep_model.fit(eval_data,eval_label,validation_data=((test_data, test_label)),epochs=20,batch_size=32,verbose=1,callbacks=[mc,mces],shuffle=False) #epochs #split #\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "109/109 [==============================] - 76s 691ms/step - loss: 0.6882 - accuracy: 0.6070 - val_loss: 0.6907 - val_accuracy: 0.6333\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.69070, saving model to deep_model3flipped_loss.hdf5\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 74s 678ms/step - loss: 0.6523 - accuracy: 0.9545 - val_loss: 0.6800 - val_accuracy: 0.7667\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.69070 to 0.68002, saving model to deep_model3flipped_loss.hdf5\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 75s 687ms/step - loss: 0.5833 - accuracy: 0.9983 - val_loss: 0.6406 - val_accuracy: 0.8333\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.68002 to 0.64056, saving model to deep_model3flipped_loss.hdf5\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 75s 688ms/step - loss: 0.4544 - accuracy: 1.0000 - val_loss: 0.5723 - val_accuracy: 0.8333\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.64056 to 0.57234, saving model to deep_model3flipped_loss.hdf5\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 81s 739ms/step - loss: 0.2911 - accuracy: 1.0000 - val_loss: 0.5108 - val_accuracy: 0.8333\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.57234 to 0.51083, saving model to deep_model3flipped_loss.hdf5\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 77s 704ms/step - loss: 0.1602 - accuracy: 1.0000 - val_loss: 0.4923 - val_accuracy: 0.8333\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.51083 to 0.49232, saving model to deep_model3flipped_loss.hdf5\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 78s 716ms/step - loss: 0.0876 - accuracy: 1.0000 - val_loss: 0.5094 - val_accuracy: 0.8333\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.49232\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 78s 713ms/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 0.5431 - val_accuracy: 0.8333\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.49232\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 76s 695ms/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 0.5812 - val_accuracy: 0.8333\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.49232\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 75s 691ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.6187 - val_accuracy: 0.8333\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.49232\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 75s 688ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.6549 - val_accuracy: 0.8333\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.49232\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 76s 694ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.6894 - val_accuracy: 0.8333\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.49232\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 73s 666ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.7219 - val_accuracy: 0.8333\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.49232\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 73s 669ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.7524 - val_accuracy: 0.8333\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.49232\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 72s 663ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.7810 - val_accuracy: 0.8333\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.49232\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 72s 659ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8080 - val_accuracy: 0.8333\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.49232\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 72s 657ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8335 - val_accuracy: 0.8333\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.49232\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 73s 666ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8578 - val_accuracy: 0.8333\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.49232\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 73s 668ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8810 - val_accuracy: 0.8333\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.49232\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 73s 668ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9029 - val_accuracy: 0.8333\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.49232\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "l600XcWYXRtb",
        "outputId": "2a8a4e2e-8ef3-4e79-f84e-c0932f09a50b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2MXK1mikKFZ"
      },
      "source": [
        "      \n",
        "test_label = to_categorical(test_label, num_classes=2)     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJiBh6svGK87"
      },
      "source": [
        "# 8-bit full integer quantization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWBm23i1op1p",
        "outputId": "90add682-af9c-4461-b7b6-9e1354d87ee5"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(deep_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quant_model = converter.convert()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp0dbsgnld/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcTsEyYa901h",
        "outputId": "2a2df339-5566-43d0-9b31-ad34f5392b20"
      },
      "source": [
        "import pathlib\n",
        "\n",
        "tflite_models_dir = pathlib.Path(\"\")\n",
        "#tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
        "'''\n",
        "# Save the unquantized/float model:\n",
        "tflite_model_file = tflite_models_dir/\"mnist_model.tflite\"\n",
        "tflite_model_file.write_bytes(tflite_model)\n",
        "'''\n",
        "# Save the quantized model:\n",
        "tflite_model_quant_file = tflite_models_dir/\"model_quant.tflite\"\n",
        "tflite_model_quant_file.write_bytes(tflite_quant_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4032160"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwBxu6Kb94e6",
        "outputId": "1e585ac1-1244-49d9-bfae-e6bcafb3f8ec"
      },
      "source": [
        "tflite_interpreter = tf.lite.Interpreter('model_quant.tflite')\n",
        "\n",
        "input_details = tflite_interpreter.get_input_details()\n",
        "output_details = tflite_interpreter.get_output_details()\n",
        "\n",
        "\n",
        "#tflite_interpreter.resize_tensor_input(input_details[0]['index'], (60, 22, 15000))\n",
        "#tflite_interpreter.resize_tensor_input(output_details[0]['index'], (60, 2))\n",
        "tflite_interpreter.allocate_tensors()\n",
        "\n",
        "\n",
        "predictions = []\n",
        "for data in test_data:\n",
        "  tflite_interpreter.set_tensor(input_details[0]['index'], [data])\n",
        "\n",
        "  tflite_interpreter.invoke()\n",
        "\n",
        "  tflite_model_predictions = tflite_interpreter.get_tensor(output_details[0]['index'])\n",
        "  print(\"Prediction results shape:\", tflite_model_predictions.shape)\n",
        "  predictions.append(tflite_model_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WADP8PNi97SL",
        "outputId": "d2859ffd-a255-45f0-e8d3-f9987012a2a5"
      },
      "source": [
        "count = 0\n",
        "for i in range(len(predictions)):\n",
        "  if (predictions[i][0][0] > predictions[i][0][1]) and (test_label[i][0] == 1):\n",
        "    count += 1\n",
        "  elif (predictions[i][0][0] < predictions[i][0][1]) and (test_label[i][1] == 1):\n",
        "    count += 1\n",
        "print(f'total correct predictions = {count}')\n",
        "print(f'accuracy = {count/60}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total correct predictions = 50\n",
            "accuracy = 0.8333333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fq66kTnEGIF-"
      },
      "source": [
        "# 16-bit float quantization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TezxL-JeBgTV",
        "outputId": "8f5db5ef-4ea7-4fb6-e4b9-3a818117bb82"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(deep_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_types = [tf.float16]\n",
        "tflite_quant_model_f = converter.convert()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpp7lf25kz/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpp7lf25kz/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2siSgNbVBkCk",
        "outputId": "21764c25-fe40-4507-f414-a0c0d77981ec"
      },
      "source": [
        "import pathlib\n",
        "\n",
        "tflite_models_dir = pathlib.Path(\"\")\n",
        "#tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
        "'''\n",
        "# Save the unquantized/float model:\n",
        "tflite_model_file = tflite_models_dir/\"mnist_model.tflite\"\n",
        "tflite_model_file.write_bytes(tflite_model)\n",
        "'''\n",
        "# Save the quantized model:\n",
        "tflite_model_quant_file = tflite_models_dir/\"model_quant_f.tflite\"\n",
        "tflite_model_quant_file.write_bytes(tflite_quant_model_f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8036656"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Tszvu58B0dD",
        "outputId": "3c8986dd-5fed-4fe1-8d29-7b901a6eacc0"
      },
      "source": [
        "tflite_interpreter = tf.lite.Interpreter('model_quant_f.tflite')\n",
        "\n",
        "input_details = tflite_interpreter.get_input_details()\n",
        "output_details = tflite_interpreter.get_output_details()\n",
        "\n",
        "\n",
        "#tflite_interpreter.resize_tensor_input(input_details[0]['index'], (60, 22, 15000))\n",
        "#tflite_interpreter.resize_tensor_input(output_details[0]['index'], (60, 2))\n",
        "tflite_interpreter.allocate_tensors()\n",
        "\n",
        "\n",
        "predictions = []\n",
        "for data in test_data:\n",
        "  tflite_interpreter.set_tensor(input_details[0]['index'], [data])\n",
        "\n",
        "  tflite_interpreter.invoke()\n",
        "\n",
        "  tflite_model_predictions = tflite_interpreter.get_tensor(output_details[0]['index'])\n",
        "  print(\"Prediction results shape:\", tflite_model_predictions.shape)\n",
        "  predictions.append(tflite_model_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsZkhgVSBmCI",
        "outputId": "137d0c4b-40e1-4626-8200-b280b8154b57"
      },
      "source": [
        "count = 0\n",
        "for i in range(len(predictions)):\n",
        "  if (predictions[i][0][0] > predictions[i][0][1]) and (test_label[i][0] == 1):\n",
        "    count += 1\n",
        "  elif (predictions[i][0][0] < predictions[i][0][1]) and (test_label[i][1] == 1):\n",
        "    count += 1\n",
        "print(f'total correct predictions = {count}')\n",
        "print(f'accuracy = {count/60}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total correct predictions = 50\n",
            "accuracy = 0.8333333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIljlPdjzhh3"
      },
      "source": [
        "# Pruning 50%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNjxU5PIBoIm"
      },
      "source": [
        "deep_model.load_weights(\"/content/deep_model3flipped_loss.hdf5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUVNC59Il4Se",
        "outputId": "55b04c7c-6192-43b9-87bc-010dbe786fac"
      },
      "source": [
        "import tempfile\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "_, deep_keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(deep_model, deep_keras_file, include_optimizer=False)\n",
        "print('Saved baseline model to:', deep_keras_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved baseline model to: /tmp/tmpzyk1urdk.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlPsgg7HoHoA",
        "outputId": "f55467cf-1553-4595-8a38-829ee48913ca"
      },
      "source": [
        "is_tfmot = True\n",
        "!pip install tensorflow_model_optimization"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_model_optimization in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.19.5)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.15.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (0.1.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMLV1u-qnW-3",
        "outputId": "8ae86dae-d988-4cfb-da35-df97d7b01d03"
      },
      "source": [
        "if not(is_tfmot):\n",
        "  !pip install tensorflow_model_optimization\n",
        "  is_tfmot = True\n",
        "\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Compute end step to finish pruning after 2 epochs.\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "#validation_split = 0.1 # 10% of training set will be used for validation set. \n",
        "\n",
        "num_images = eval_data.shape[0]\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "\n",
        "# Define model for pruning.\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.20,\n",
        "                                                               final_sparsity=0.50,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step,\n",
        "                                                               frequency=5)\n",
        "}\n",
        "\n",
        "model_for_pruning = prune_low_magnitude(deep_model, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_for_pruning.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 22, 15000)]       0         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d ( (None, 22, 25)            7500027   \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 8, 25)             1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d_1 (None, 8, 50)             25052     \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 3, 50)             1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d_2 (None, 3, 100)            100102    \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 1, 100)            1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d_3 (None, 1, 200)            400202    \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 1, 200)            1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_flatten  (None, 200)               1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense (P (None, 2)                 804       \n",
            "=================================================================\n",
            "Total params: 8,026,192\n",
            "Trainable params: 4,013,277\n",
            "Non-trainable params: 4,012,915\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tgpK604n9I1",
        "outputId": "b643cbf5-9995-47d4-f121-64e7c186e8f2"
      },
      "source": [
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "\n",
        "hist = model_for_pruning.fit(eval_data, eval_label, validation_data=(test_data, test_label), epochs=10, batch_size=32, verbose=1, callbacks=callbacks) #epochs #split #"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "109/109 [==============================] - 110s 965ms/step - loss: 0.4388 - accuracy: 0.8762 - val_loss: 0.9259 - val_accuracy: 0.8000\n",
            "Epoch 2/10\n",
            "109/109 [==============================] - 106s 972ms/step - loss: 0.0094 - accuracy: 0.9985 - val_loss: 1.5582 - val_accuracy: 0.8000\n",
            "Epoch 3/10\n",
            "109/109 [==============================] - 105s 967ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.9341 - val_accuracy: 0.8000\n",
            "Epoch 4/10\n",
            "109/109 [==============================] - 106s 976ms/step - loss: 4.2029e-04 - accuracy: 1.0000 - val_loss: 2.1796 - val_accuracy: 0.8000\n",
            "Epoch 5/10\n",
            "109/109 [==============================] - 105s 965ms/step - loss: 2.1571e-04 - accuracy: 1.0000 - val_loss: 2.2973 - val_accuracy: 0.8000\n",
            "Epoch 6/10\n",
            "109/109 [==============================] - 107s 976ms/step - loss: 8.3778e-05 - accuracy: 1.0000 - val_loss: 2.5496 - val_accuracy: 0.8000\n",
            "Epoch 7/10\n",
            "109/109 [==============================] - 106s 976ms/step - loss: 3.6528e-05 - accuracy: 1.0000 - val_loss: 2.7837 - val_accuracy: 0.8000\n",
            "Epoch 8/10\n",
            "109/109 [==============================] - 107s 985ms/step - loss: 1.7536e-05 - accuracy: 1.0000 - val_loss: 3.0244 - val_accuracy: 0.8000\n",
            "Epoch 9/10\n",
            "109/109 [==============================] - 106s 977ms/step - loss: 1.0905e-05 - accuracy: 1.0000 - val_loss: 3.1430 - val_accuracy: 0.8000\n",
            "Epoch 10/10\n",
            "109/109 [==============================] - 105s 966ms/step - loss: 6.5027e-06 - accuracy: 1.0000 - val_loss: 3.2516 - val_accuracy: 0.8000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0oCx3glydIO"
      },
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksZOB6jZoQ_e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15b3b29a-a7a2-4027-93fd-5dcb239565fb"
      },
      "source": [
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "_, deep_pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model_for_export, deep_pruned_keras_file, include_optimizer=False)\n",
        "print('Saved pruned Keras model to:', deep_pruned_keras_file)\n",
        "\n",
        "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(deep_keras_file)))\n",
        "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(deep_pruned_keras_file)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved pruned Keras model to: /tmp/tmpb6ggs64n.h5\n",
            "Size of gzipped baseline Keras model: 14720820.00 bytes\n",
            "Size of gzipped pruned Keras model: 9120122.00 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5u6JOZWzm0d"
      },
      "source": [
        "# Pruning 60%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypxw7m8-yU_T",
        "outputId": "0e55f5d1-67ff-4834-dbcf-af524bc49962"
      },
      "source": [
        "!pip install tensorflow_model_optimization\n",
        "is_tfmot = True\n",
        "\n",
        "if not(is_tfmot):\n",
        "  !pip install tensorflow_model_optimization\n",
        "  is_tfmot = True\n",
        "\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Compute end step to finish pruning after 2 epochs.\n",
        "batch_size = 32\n",
        "epochs = 20\n",
        "#validation_split = 0.1 # 10% of training set will be used for validation set. \n",
        "\n",
        "num_images = eval_data.shape[0]\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "\n",
        "# Define model for pruning.\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.20,\n",
        "                                                               final_sparsity=0.60,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step,\n",
        "                                                               frequency=3)\n",
        "}\n",
        "\n",
        "model_for_pruning = 0\n",
        "model_for_pruning = prune_low_magnitude(deep_model, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_for_pruning.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_model_optimization in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.19.5)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (0.1.6)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.15.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 22, 15000)]       0         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d ( (None, 22, 25)            7500027   \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 8, 25)             1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d_1 (None, 8, 50)             25052     \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 3, 50)             1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d_2 (None, 3, 100)            100102    \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 1, 100)            1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d_3 (None, 1, 200)            400202    \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 1, 200)            1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_flatten  (None, 200)               1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense (P (None, 2)                 804       \n",
            "=================================================================\n",
            "Total params: 8,026,192\n",
            "Trainable params: 4,013,277\n",
            "Non-trainable params: 4,012,915\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNndm5IczvGi",
        "outputId": "cf6dc0fe-265f-4a9d-ec57-71c22e52974d"
      },
      "source": [
        "import tempfile\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "\n",
        "hist = model_for_pruning.fit(eval_data, eval_label, validation_data=(test_data, test_label), epochs=10, batch_size=128, verbose=1, callbacks=callbacks) #epochs #split #"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "28/28 [==============================] - 87s 3s/step - loss: 0.1515 - accuracy: 0.9673 - val_loss: 1.2057 - val_accuracy: 0.7833\n",
            "Epoch 2/10\n",
            "28/28 [==============================] - 90s 3s/step - loss: 0.0643 - accuracy: 0.9822 - val_loss: 1.4555 - val_accuracy: 0.8000\n",
            "Epoch 3/10\n",
            "28/28 [==============================] - 83s 3s/step - loss: 0.0191 - accuracy: 0.9961 - val_loss: 1.5937 - val_accuracy: 0.7833\n",
            "Epoch 4/10\n",
            "28/28 [==============================] - 82s 3s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.0127 - val_accuracy: 0.8167\n",
            "Epoch 5/10\n",
            "28/28 [==============================] - 81s 3s/step - loss: 6.7686e-04 - accuracy: 1.0000 - val_loss: 1.9696 - val_accuracy: 0.8000\n",
            "Epoch 6/10\n",
            "28/28 [==============================] - 81s 3s/step - loss: 2.8378e-04 - accuracy: 1.0000 - val_loss: 2.0362 - val_accuracy: 0.8000\n",
            "Epoch 7/10\n",
            "28/28 [==============================] - 83s 3s/step - loss: 1.7436e-04 - accuracy: 1.0000 - val_loss: 2.3684 - val_accuracy: 0.8167\n",
            "Epoch 8/10\n",
            "28/28 [==============================] - 82s 3s/step - loss: 9.8840e-05 - accuracy: 1.0000 - val_loss: 2.5890 - val_accuracy: 0.8167\n",
            "Epoch 9/10\n",
            "28/28 [==============================] - 82s 3s/step - loss: 5.7523e-05 - accuracy: 1.0000 - val_loss: 2.7508 - val_accuracy: 0.8167\n",
            "Epoch 10/10\n",
            "28/28 [==============================] - 83s 3s/step - loss: 4.0903e-05 - accuracy: 1.0000 - val_loss: 2.9256 - val_accuracy: 0.8167\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vN18hqgWzxaf",
        "outputId": "dc781d2c-05a2-4ecf-a751-8e8d19cd71a0"
      },
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)\n",
        "\n",
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "_, deep_pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model_for_export, deep_pruned_keras_file, include_optimizer=False)\n",
        "print('Saved pruned Keras model to:', deep_pruned_keras_file)\n",
        "\n",
        "#print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(deep_keras_file)))\n",
        "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(deep_pruned_keras_file)))\n",
        "\n",
        "model_for_export = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved pruned Keras model to: /tmp/tmp63ole3yf.h5\n",
            "Size of gzipped pruned Keras model: 11295620.00 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8l8zyH1eTX6X",
        "outputId": "841b924b-3b8c-4286-c757-6e6cf811ba3a"
      },
      "source": [
        "import tempfile\n",
        "import os\n",
        "\n",
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)\n",
        "\n",
        "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(\"/tmp/tmp_nc6yncf.h5\")))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of gzipped baseline Keras model: 11776838.00 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luncYFyG0Ycp"
      },
      "source": [
        "# Pruning 70%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcPquRndZAGe"
      },
      "source": [
        "deep_model.load_weights(\"/content/deep_model3flipped_loss.hdf5\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pB27Dx0_0RsJ",
        "outputId": "baf6195d-b883-4e02-bfe0-4c1a42f36d0d"
      },
      "source": [
        "deep_model.load_weights(\"/content/deep_model3flipped_loss.hdf5\")\n",
        "\n",
        "\n",
        "!pip install tensorflow_model_optimization\n",
        "is_tfmot = True\n",
        "\n",
        "\n",
        "if not(is_tfmot):\n",
        "  !pip install tensorflow_model_optimization\n",
        "  is_tfmot = True\n",
        "\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Compute end step to finish pruning after 2 epochs.\n",
        "batch_size = 32\n",
        "epochs = 5\n",
        "#validation_split = 0.1 # 10% of training set will be used for validation set. \n",
        "\n",
        "num_images = eval_data.shape[0]\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "\n",
        "# Define model for pruning.\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.20,\n",
        "                                                               final_sparsity=0.70,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step,\n",
        "                                                               frequency=100)\n",
        "}\n",
        "\n",
        "model_for_pruning = prune_low_magnitude(deep_model, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_for_pruning.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_model_optimization in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.19.5)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (0.1.6)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.15.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 22, 15000)]       0         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d ( (None, 22, 25)            7500027   \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 8, 25)             1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d_1 (None, 8, 50)             25052     \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 3, 50)             1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d_2 (None, 3, 100)            100102    \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 1, 100)            1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d_3 (None, 1, 200)            400202    \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 1, 200)            1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_flatten  (None, 200)               1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense (P (None, 2)                 804       \n",
            "=================================================================\n",
            "Total params: 8,026,192\n",
            "Trainable params: 4,013,277\n",
            "Non-trainable params: 4,012,915\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_aoDEjz0dZU",
        "outputId": "584c4a24-8714-40c2-f87d-51a7bd780f69"
      },
      "source": [
        "import tempfile\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "\n",
        "hist = model_for_pruning.fit(eval_data, eval_label, validation_data=(test_data, test_label), epochs=5, batch_size=32, verbose=1, callbacks=callbacks) #epochs #split #"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "109/109 [==============================] - 90s 781ms/step - loss: 0.3442 - accuracy: 0.8872 - val_loss: 0.7114 - val_accuracy: 0.8333\n",
            "Epoch 2/5\n",
            "109/109 [==============================] - 86s 786ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.1625 - val_accuracy: 0.8333\n",
            "Epoch 3/5\n",
            "109/109 [==============================] - 86s 785ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.1378 - val_accuracy: 0.8333\n",
            "Epoch 4/5\n",
            "109/109 [==============================] - 86s 791ms/step - loss: 7.7656e-04 - accuracy: 1.0000 - val_loss: 1.3321 - val_accuracy: 0.8333\n",
            "Epoch 5/5\n",
            "109/109 [==============================] - 95s 868ms/step - loss: 1.9991e-04 - accuracy: 1.0000 - val_loss: 1.6486 - val_accuracy: 0.8333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnV597mh0kUV",
        "outputId": "32be9243-1c5d-493a-96e5-c3ad44344a73"
      },
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)\n",
        "\n",
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "_, deep_pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model_for_export, deep_pruned_keras_file, include_optimizer=False)\n",
        "print('Saved pruned Keras model to:', deep_pruned_keras_file)\n",
        "\n",
        "#print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(deep_keras_file)))\n",
        "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(deep_pruned_keras_file)))\n",
        "\n",
        "model_for_export = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved pruned Keras model to: /tmp/tmpkx5_69jt.h5\n",
            "Size of gzipped pruned Keras model: 6211741.00 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBBcRaZH050D"
      },
      "source": [
        "# Pruning 80%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JemRiqJf0mgc",
        "outputId": "f057bf15-427e-4026-9cfe-7a1471517347"
      },
      "source": [
        "deep_model.load_weights(\"/content/deep_model3flipped_loss.hdf5\")\n",
        "\n",
        "\n",
        "!pip install tensorflow_model_optimization\n",
        "is_tfmot = True\n",
        "\n",
        "\n",
        "if not(is_tfmot):\n",
        "  !pip install tensorflow_model_optimization\n",
        "  is_tfmot = True\n",
        "\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Compute end step to finish pruning after 2 epochs.\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "#validation_split = 0.1 # 10% of training set will be used for validation set. \n",
        "\n",
        "num_images = eval_data.shape[0]\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "\n",
        "# Define model for pruning.\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.30,\n",
        "                                                               final_sparsity=0.80,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step,\n",
        "                                                               frequency=5)\n",
        "}\n",
        "\n",
        "model_for_pruning = prune_low_magnitude(deep_model, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_for_pruning.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_model_optimization in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (0.1.6)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.15.0)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.19.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 22, 15000)]       0         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d ( (None, 22, 25)            7500027   \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 8, 25)             1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d_1 (None, 8, 50)             25052     \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 3, 50)             1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d_2 (None, 3, 100)            100102    \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 1, 100)            1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d_3 (None, 1, 200)            400202    \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 1, 200)            1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_flatten  (None, 200)               1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense (P (None, 2)                 804       \n",
            "=================================================================\n",
            "Total params: 8,026,192\n",
            "Trainable params: 4,013,277\n",
            "Non-trainable params: 4,012,915\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6FX0OQu1F6n",
        "outputId": "1132892c-f7ca-4e7a-9add-3030ab45e124"
      },
      "source": [
        "import tempfile\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "\n",
        "hist = model_for_pruning.fit(eval_data, eval_label, validation_data=(test_data, test_label), epochs=10, batch_size=32, verbose=1, callbacks=callbacks) #epochs #split #"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "28/28 [==============================] - 84s 3s/step - loss: 0.1199 - accuracy: 0.9771 - val_loss: 1.2080 - val_accuracy: 0.8000\n",
            "Epoch 2/10\n",
            "28/28 [==============================] - 78s 3s/step - loss: 0.0744 - accuracy: 0.9813 - val_loss: 1.4032 - val_accuracy: 0.8167\n",
            "Epoch 3/10\n",
            "28/28 [==============================] - 76s 3s/step - loss: 0.0229 - accuracy: 0.9928 - val_loss: 1.3915 - val_accuracy: 0.8000\n",
            "Epoch 4/10\n",
            "28/28 [==============================] - 77s 3s/step - loss: 0.0079 - accuracy: 0.9978 - val_loss: 1.7471 - val_accuracy: 0.8333\n",
            "Epoch 5/10\n",
            "28/28 [==============================] - 85s 3s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4286 - val_accuracy: 0.8000\n",
            "Epoch 6/10\n",
            "28/28 [==============================] - 80s 3s/step - loss: 6.0630e-04 - accuracy: 1.0000 - val_loss: 1.6223 - val_accuracy: 0.8167\n",
            "Epoch 7/10\n",
            "28/28 [==============================] - 88s 3s/step - loss: 4.3069e-04 - accuracy: 1.0000 - val_loss: 1.5682 - val_accuracy: 0.8167\n",
            "Epoch 8/10\n",
            "28/28 [==============================] - 82s 3s/step - loss: 3.6256e-04 - accuracy: 1.0000 - val_loss: 1.7083 - val_accuracy: 0.8167\n",
            "Epoch 9/10\n",
            "28/28 [==============================] - 83s 3s/step - loss: 2.6955e-04 - accuracy: 1.0000 - val_loss: 1.7047 - val_accuracy: 0.8167\n",
            "Epoch 10/10\n",
            "28/28 [==============================] - 81s 3s/step - loss: 2.5963e-04 - accuracy: 1.0000 - val_loss: 1.6774 - val_accuracy: 0.8167\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxLvdpDH1IUa",
        "outputId": "69b42269-6ea5-47a9-e242-0862ff2b62b0"
      },
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)\n",
        "\n",
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "_, deep_pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model_for_export, deep_pruned_keras_file, include_optimizer=False)\n",
        "print('Saved pruned Keras model to:', deep_pruned_keras_file)\n",
        "\n",
        "#print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(deep_keras_file)))\n",
        "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(deep_pruned_keras_file)))\n",
        "\n",
        "model_for_export = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved pruned Keras model to: /tmp/tmpx5c2naa7.h5\n",
            "Size of gzipped pruned Keras model: 7873765.00 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v41ZHG_D2zCa"
      },
      "source": [
        "# Pruning 90%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfV2pLOM1JqK",
        "outputId": "183403a9-3cda-461e-9fd8-dfc369e89a45"
      },
      "source": [
        "deep_model.load_weights(\"/content/deep_model3flipped_loss.hdf5\")\n",
        "\n",
        "\n",
        "\n",
        "!pip install tensorflow_model_optimization\n",
        "is_tfmot = True\n",
        "\n",
        "if not(is_tfmot):\n",
        "  !pip install tensorflow_model_optimization\n",
        "  is_tfmot = True\n",
        "\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Compute end step to finish pruning after 2 epochs.\n",
        "batch_size = 32\n",
        "epochs = 20\n",
        "#validation_split = 0.1 # 10% of training set will be used for validation set. \n",
        "\n",
        "num_images = eval_data.shape[0]\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "\n",
        "# Define model for pruning.\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.30,\n",
        "                                                               final_sparsity=0.90,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step,\n",
        "                                                               frequency=5)\n",
        "}\n",
        "\n",
        "model_for_pruning = 0\n",
        "model_for_pruning = prune_low_magnitude(deep_model, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_for_pruning.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_model_optimization in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.15.0)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.19.5)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (0.1.6)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 22, 15000)]       0         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d ( (None, 22, 25)            7500027   \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 8, 25)             1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d_1 (None, 8, 50)             25052     \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 3, 50)             1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d_2 (None, 3, 100)            100102    \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 1, 100)            1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d_3 (None, 1, 200)            400202    \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 1, 200)            1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_flatten  (None, 200)               1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense (P (None, 2)                 804       \n",
            "=================================================================\n",
            "Total params: 8,026,192\n",
            "Trainable params: 4,013,277\n",
            "Non-trainable params: 4,012,915\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xm9zbqZh25bg",
        "outputId": "6bad51ad-ccb2-4e0c-b9fa-a0c4c891f236"
      },
      "source": [
        "import tempfile\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "\n",
        "hist = model_for_pruning.fit(eval_data, eval_label, validation_data=(test_data, test_label), epochs=20, batch_size=32, verbose=1, callbacks=callbacks) #epochs #split #"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "109/109 [==============================] - 113s 990ms/step - loss: 0.3376 - accuracy: 0.8989 - val_loss: 0.7952 - val_accuracy: 0.8333\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 108s 991ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.4846 - val_accuracy: 0.8333\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 109s 1s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3645 - val_accuracy: 0.8333\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 109s 999ms/step - loss: 3.7867e-04 - accuracy: 1.0000 - val_loss: 1.4834 - val_accuracy: 0.8333\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 109s 999ms/step - loss: 2.6243e-04 - accuracy: 1.0000 - val_loss: 1.4914 - val_accuracy: 0.8333\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 110s 1s/step - loss: 2.2494e-04 - accuracy: 1.0000 - val_loss: 1.5413 - val_accuracy: 0.8167\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 111s 1s/step - loss: 2.4149e-04 - accuracy: 1.0000 - val_loss: 1.5961 - val_accuracy: 0.8333\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 111s 1s/step - loss: 1.6672e-04 - accuracy: 1.0000 - val_loss: 1.6103 - val_accuracy: 0.8167\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 110s 1s/step - loss: 1.2193e-04 - accuracy: 1.0000 - val_loss: 1.6636 - val_accuracy: 0.8167\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 109s 1s/step - loss: 1.2367e-04 - accuracy: 1.0000 - val_loss: 1.7562 - val_accuracy: 0.8167\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 109s 998ms/step - loss: 7.7766e-05 - accuracy: 1.0000 - val_loss: 1.9167 - val_accuracy: 0.8333\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 110s 1s/step - loss: 6.9393e-05 - accuracy: 1.0000 - val_loss: 1.9161 - val_accuracy: 0.8333\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 109s 1s/step - loss: 5.5156e-05 - accuracy: 1.0000 - val_loss: 1.9565 - val_accuracy: 0.8333\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 110s 1s/step - loss: 4.3965e-05 - accuracy: 1.0000 - val_loss: 2.0315 - val_accuracy: 0.8333\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 109s 997ms/step - loss: 4.1180e-05 - accuracy: 1.0000 - val_loss: 2.0237 - val_accuracy: 0.8333\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 109s 1s/step - loss: 2.8824e-05 - accuracy: 1.0000 - val_loss: 2.0596 - val_accuracy: 0.8333\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 109s 1s/step - loss: 2.2122e-05 - accuracy: 1.0000 - val_loss: 2.1497 - val_accuracy: 0.8333\n",
            "Epoch 18/20\n",
            " 16/109 [===>..........................] - ETA: 1:33 - loss: 1.6464e-05 - accuracy: 1.0000"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BN4DPfPL27Zm",
        "outputId": "a42c6867-901d-4c4b-d501-7eeee469d162"
      },
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)\n",
        "\n",
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "_, deep_pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model_for_export, deep_pruned_keras_file, include_optimizer=False)\n",
        "print('Saved pruned Keras model to:', deep_pruned_keras_file)\n",
        "\n",
        "#print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(deep_keras_file)))\n",
        "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(deep_pruned_keras_file)))\n",
        "\n",
        "model_for_export = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved pruned Keras model to: /tmp/tmpv0nxxx0p.h5\n",
            "Size of gzipped pruned Keras model: 3048885.00 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EPYsGy52_yP"
      },
      "source": [
        "# Pruning 95%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GV9kK0zq28yX",
        "outputId": "7623d047-ecfb-48ae-e25b-c4bd0f537c27"
      },
      "source": [
        "deep_model.load_weights(\"/content/deep_model3flipped_loss.hdf5\")\n",
        "\n",
        "\n",
        "\n",
        "!pip install tensorflow_model_optimization\n",
        "is_tfmot = True\n",
        "\n",
        "if not(is_tfmot):\n",
        "  !pip install tensorflow_model_optimization\n",
        "  is_tfmot = True\n",
        "\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Compute end step to finish pruning after 2 epochs.\n",
        "batch_size = 32\n",
        "epochs = 20\n",
        "#validation_split = 0.1 # 10% of training set will be used for validation set. \n",
        "\n",
        "num_images = eval_data.shape[0]\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "\n",
        "# Define model for pruning.\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.30,\n",
        "                                                               final_sparsity=0.95,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step,\n",
        "                                                               frequency=5)\n",
        "}\n",
        "\n",
        "model_for_pruning = 0\n",
        "model_for_pruning = prune_low_magnitude(deep_model, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_for_pruning.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_model_optimization in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.19.5)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (0.1.6)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.15.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 22, 15000)]       0         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d ( (None, 22, 25)            7500027   \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 8, 25)             1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d_1 (None, 8, 50)             25052     \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 3, 50)             1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d_2 (None, 3, 100)            100102    \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 1, 100)            1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d_3 (None, 1, 200)            400202    \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 1, 200)            1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_flatten  (None, 200)               1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense (P (None, 2)                 804       \n",
            "=================================================================\n",
            "Total params: 8,026,192\n",
            "Trainable params: 4,013,277\n",
            "Non-trainable params: 4,012,915\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e_VIi7s3EJ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fbb526f-0274-4db3-8cb5-e42b4c1c9241"
      },
      "source": [
        "import tempfile\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "\n",
        "hist = model_for_pruning.fit(eval_data, eval_label, validation_data=(test_data, test_label), epochs=20, batch_size=32, verbose=1, callbacks=callbacks) #epochs #split #"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "109/109 [==============================] - 116s 1s/step - loss: 0.3404 - accuracy: 0.8960 - val_loss: 0.9621 - val_accuracy: 0.8333\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 114s 1s/step - loss: 0.0097 - accuracy: 0.9981 - val_loss: 1.5163 - val_accuracy: 0.8167\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 113s 1s/step - loss: 7.4085e-04 - accuracy: 1.0000 - val_loss: 1.8165 - val_accuracy: 0.8167\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 112s 1s/step - loss: 2.4413e-04 - accuracy: 1.0000 - val_loss: 1.8336 - val_accuracy: 0.8167\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 112s 1s/step - loss: 1.3968e-04 - accuracy: 1.0000 - val_loss: 1.8459 - val_accuracy: 0.8167\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 114s 1s/step - loss: 1.1257e-04 - accuracy: 1.0000 - val_loss: 1.8458 - val_accuracy: 0.8167\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 114s 1s/step - loss: 7.8808e-05 - accuracy: 1.0000 - val_loss: 2.0001 - val_accuracy: 0.8167\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 114s 1s/step - loss: 6.0499e-05 - accuracy: 1.0000 - val_loss: 2.1383 - val_accuracy: 0.8167\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 115s 1s/step - loss: 4.7815e-05 - accuracy: 1.0000 - val_loss: 2.2204 - val_accuracy: 0.8167\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 113s 1s/step - loss: 4.5207e-05 - accuracy: 1.0000 - val_loss: 2.0188 - val_accuracy: 0.8167\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 114s 1s/step - loss: 5.1302e-05 - accuracy: 1.0000 - val_loss: 1.8655 - val_accuracy: 0.8167\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 115s 1s/step - loss: 5.9008e-05 - accuracy: 1.0000 - val_loss: 1.9128 - val_accuracy: 0.8167\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 116s 1s/step - loss: 5.3472e-05 - accuracy: 1.0000 - val_loss: 1.8897 - val_accuracy: 0.8167\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 115s 1s/step - loss: 4.4903e-05 - accuracy: 1.0000 - val_loss: 1.7537 - val_accuracy: 0.8167\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 115s 1s/step - loss: 3.7559e-05 - accuracy: 1.0000 - val_loss: 1.8782 - val_accuracy: 0.8167\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 117s 1s/step - loss: 2.9183e-05 - accuracy: 1.0000 - val_loss: 1.9400 - val_accuracy: 0.8167\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 116s 1s/step - loss: 2.0900e-05 - accuracy: 1.0000 - val_loss: 1.8456 - val_accuracy: 0.8167\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 117s 1s/step - loss: 1.4281e-05 - accuracy: 1.0000 - val_loss: 1.8634 - val_accuracy: 0.8167\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 116s 1s/step - loss: 1.1169e-05 - accuracy: 1.0000 - val_loss: 1.8605 - val_accuracy: 0.8167\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 115s 1s/step - loss: 7.0428e-06 - accuracy: 1.0000 - val_loss: 1.9094 - val_accuracy: 0.8167\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvLmAFld3Gac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "723f72b3-db77-4f3f-b34c-fa85fe9bf9d1"
      },
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)\n",
        "\n",
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "_, deep_pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model_for_export, deep_pruned_keras_file, include_optimizer=False)\n",
        "print('Saved pruned Keras model to:', deep_pruned_keras_file)\n",
        "\n",
        "#print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(deep_keras_file)))\n",
        "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(deep_pruned_keras_file)))\n",
        "\n",
        "model_for_export = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved pruned Keras model to: /tmp/tmpdscoil7y.h5\n",
            "Size of gzipped pruned Keras model: 2158409.00 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo69-n4ZyVt8"
      },
      "source": [
        "# Pruning 99%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJ5BD6ba3IFc",
        "outputId": "ec400fb7-19d7-4309-f96a-fab52be6ad29"
      },
      "source": [
        "deep_model.load_weights(\"/content/deep_model3flipped_loss.hdf5\")\n",
        "\n",
        "model_for_export = 0\n",
        "\n",
        "!pip install tensorflow_model_optimization\n",
        "is_tfmot = True\n",
        "\n",
        "if not(is_tfmot):\n",
        "  !pip install tensorflow_model_optimization\n",
        "  is_tfmot = True\n",
        "\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Compute end step to finish pruning after 2 epochs.\n",
        "batch_size = 32\n",
        "epochs = 20\n",
        "#validation_split = 0.1 # 10% of training set will be used for validation set. \n",
        "\n",
        "num_images = eval_data.shape[0]\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "\n",
        "# Define model for pruning.\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.30,\n",
        "                                                               final_sparsity=0.99,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step,\n",
        "                                                               frequency=5)\n",
        "}\n",
        "\n",
        "model_for_pruning = 0\n",
        "model_for_pruning = prune_low_magnitude(deep_model, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_for_pruning.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_model_optimization in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (0.1.6)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.19.5)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.15.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 22, 15000)]       0         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d ( (None, 22, 25)            7500027   \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 8, 25)             1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d_1 (None, 8, 50)             25052     \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 3, 50)             1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d_2 (None, 3, 100)            100102    \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 1, 100)            1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d_3 (None, 1, 200)            400202    \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 1, 200)            1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_flatten  (None, 200)               1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense (P (None, 2)                 804       \n",
            "=================================================================\n",
            "Total params: 8,026,192\n",
            "Trainable params: 4,013,277\n",
            "Non-trainable params: 4,012,915\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKJCw8buyuXD",
        "outputId": "b16f07d4-1547-41fe-fb60-534e41cba965"
      },
      "source": [
        "import tempfile\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "\n",
        "hist = model_for_pruning.fit(eval_data, eval_label, validation_data=(test_data, test_label), epochs=20, batch_size=32, verbose=1, callbacks=callbacks) #epochs #split #"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "109/109 [==============================] - 112s 973ms/step - loss: 0.3685 - accuracy: 0.8993 - val_loss: 0.9083 - val_accuracy: 0.8000\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 109s 1s/step - loss: 0.0102 - accuracy: 0.9981 - val_loss: 1.5761 - val_accuracy: 0.8333\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 111s 1s/step - loss: 8.7574e-04 - accuracy: 1.0000 - val_loss: 1.8767 - val_accuracy: 0.8167\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 112s 1s/step - loss: 4.1084e-04 - accuracy: 1.0000 - val_loss: 1.9063 - val_accuracy: 0.8167\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 111s 1s/step - loss: 2.9462e-04 - accuracy: 1.0000 - val_loss: 1.9494 - val_accuracy: 0.8167\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 112s 1s/step - loss: 2.0954e-04 - accuracy: 1.0000 - val_loss: 2.0133 - val_accuracy: 0.8167\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 113s 1s/step - loss: 1.1850e-04 - accuracy: 1.0000 - val_loss: 2.0938 - val_accuracy: 0.8333\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 111s 1s/step - loss: 9.2667e-05 - accuracy: 1.0000 - val_loss: 2.0882 - val_accuracy: 0.8167\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 113s 1s/step - loss: 9.2926e-05 - accuracy: 1.0000 - val_loss: 2.1920 - val_accuracy: 0.8167\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 110s 1s/step - loss: 1.1949e-04 - accuracy: 1.0000 - val_loss: 2.0368 - val_accuracy: 0.8000\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 111s 1s/step - loss: 1.1526e-04 - accuracy: 1.0000 - val_loss: 1.9875 - val_accuracy: 0.8000\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 111s 1s/step - loss: 1.4039e-04 - accuracy: 1.0000 - val_loss: 1.8418 - val_accuracy: 0.8000\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 111s 1s/step - loss: 1.5489e-04 - accuracy: 1.0000 - val_loss: 1.7259 - val_accuracy: 0.8000\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 111s 1s/step - loss: 2.0150e-04 - accuracy: 1.0000 - val_loss: 1.7301 - val_accuracy: 0.8167\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 111s 1s/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 1.8312 - val_accuracy: 0.7667\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 111s 1s/step - loss: 0.0925 - accuracy: 0.9778 - val_loss: 1.4222 - val_accuracy: 0.7000\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 110s 1s/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 1.2427 - val_accuracy: 0.7833\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 111s 1s/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.0011 - val_accuracy: 0.7833\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 111s 1s/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.0780 - val_accuracy: 0.7833\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 110s 1s/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.1283 - val_accuracy: 0.7833\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lHkM3o9yg8r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d978554-efe3-48bd-8d45-a54305b0eaee"
      },
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)\n",
        "\n",
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "_, deep_pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model_for_export, deep_pruned_keras_file, include_optimizer=False)\n",
        "print('Saved pruned Keras model to:', deep_pruned_keras_file)\n",
        "\n",
        "#print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(deep_keras_file)))\n",
        "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(deep_pruned_keras_file)))\n",
        "\n",
        "model_for_export = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved pruned Keras model to: /tmp/tmpm3yy6m50.h5\n",
            "Size of gzipped pruned Keras model: 1337353.00 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwZ-_WjPyzST"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}