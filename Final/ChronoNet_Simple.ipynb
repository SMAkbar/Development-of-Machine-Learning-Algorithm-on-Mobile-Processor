{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ChronoNet-Simple.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHQDMmcFVYbB"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "eval_data_original = np.load(\"/content/drive/MyDrive/Colab Notebooks/eval_data_complete.npy\")\n",
        "eval_label_original = np.load(\"/content/drive/MyDrive/Colab Notebooks/eval_label_complete.npy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn6LsTfQWDHy"
      },
      "source": [
        "eval_data = eval_data_original[10:-50]\n",
        "eval_label = eval_label_original[10:-50]\n",
        "\n",
        "test_data = np.concatenate((eval_data_original[:10], eval_data_original[-50:]))\n",
        "test_label = np.concatenate((eval_label_original[:10], eval_label_original[-50:]))\n",
        "\n",
        "eval_data_original = 0\n",
        "eval_label_original = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pj91quNYWrH5",
        "outputId": "344a9270-675e-4cac-c193-743513c7afb0"
      },
      "source": [
        "eval_data = np.concatenate((eval_data[:337], eval_data[:337], eval_data[:337], eval_data[:337], eval_data))\n",
        "eval_label = np.concatenate((eval_label[:337], eval_label[:337], eval_label[:337], eval_label[:337], eval_label))\n",
        "print(eval_data.shape)\n",
        "print(eval_label.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3483, 22, 15000)\n",
            "(3483,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCfwx8GFW1gL"
      },
      "source": [
        "idx = np.random.permutation(len(eval_data))\n",
        "eval_data,eval_label = eval_data[idx], eval_label[idx]\n",
        "idx = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rq2HZNDxW7zs",
        "outputId": "7deb6ed1-e78c-4083-b6a6-e003f6ca898d"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "enc_labels = to_categorical(eval_label, num_classes=2)      \n",
        "test_label = to_categorical(test_label, num_classes=2)           \n",
        "eval_label= enc_labels\n",
        "enc_labels = 0\n",
        "print(eval_data.shape)\n",
        "print(eval_label.shape)\n",
        "print(eval_data.dtype)\n",
        "print(eval_label.dtype)\n",
        "print('training labels have been loaded')\n",
        "\n",
        "bs,t,f = eval_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3483, 22, 15000)\n",
            "(3483, 2)\n",
            "float32\n",
            "float32\n",
            "training labels have been loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_FtBAVuXHU6",
        "outputId": "15a1abec-c547-489a-a020-3ff9712ea122"
      },
      "source": [
        "from pdb import set_trace\n",
        "#import mne\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import os\n",
        "import h5py\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN,LSTM, Dense, Activation, Bidirectional\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Convolution2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "# ----------------------CHRONONET Testing-----------------------\n",
        "from tensorflow.keras.layers import Input,Dense,concatenate,Flatten,GRU,Conv1D\n",
        "from tensorflow.keras.models import Model\n",
        "inputsin= Input(shape=(t,f))\n",
        "# ------------------First Inception\n",
        "tower1 = Conv1D(32, 2, strides=2,activation='relu',padding=\"causal\")(inputsin)\n",
        "tower1 = BatchNormalization()(tower1)\n",
        "tower2 = Conv1D(32, 4, strides=2,activation='relu',padding=\"causal\")(inputsin)\n",
        "tower2 = BatchNormalization()(tower2)\n",
        "tower3 = Conv1D(32, 8, strides=2,activation='relu',padding=\"causal\")(inputsin)\n",
        "tower3 = BatchNormalization()(tower3)\n",
        "x = concatenate([tower1,tower2,tower3],axis=2)\n",
        "x = Dropout(0.45)(x)\n",
        "\n",
        "# ----------------------Second Inception\n",
        "tower1 = Conv1D(32, 2, strides=2,activation='relu',padding=\"causal\")(x)\n",
        "tower1 = BatchNormalization()(tower1)\n",
        "tower2 = Conv1D(32, 4, strides=2,activation='relu',padding=\"causal\")(x)\n",
        "tower2 = BatchNormalization()(tower2)\n",
        "tower3 = Conv1D(32, 8, strides=2,activation='relu',padding=\"causal\")(x)\n",
        "tower3 = BatchNormalization()(tower3)\n",
        "x = concatenate([tower1,tower2,tower3],axis=2)\n",
        "x = Dropout(0.45)(x)\n",
        "\n",
        "# ----------------------------------Third Inception\n",
        "tower1 = Conv1D(32, 2, strides=2,activation='relu',padding=\"causal\")(x)\n",
        "tower1 = BatchNormalization()(tower1)\n",
        "tower2 = Conv1D(32, 4, strides=2,activation='relu',padding=\"causal\")(x)\n",
        "tower2 = BatchNormalization()(tower2)\n",
        "tower3 = Conv1D(32, 8, strides=2,activation='relu',padding=\"causal\")(x)\n",
        "tower3 = BatchNormalization()(tower3)\n",
        "x = concatenate([tower1,tower2,tower3],axis=2)\n",
        "x = Dropout(0.45)(x)\n",
        "\n",
        "res1 = GRU(32,activation='tanh',return_sequences=True)(x)\n",
        "res2 = GRU(32,activation='tanh',return_sequences=True)(res1)\n",
        "res1_2 = concatenate([res1,res2],axis=2)\n",
        "res3 = GRU(32,activation='tanh',return_sequences=True)(res1_2)\n",
        "x = concatenate([res1,res2,res3])\n",
        "x = GRU(32,activation='tanh')(x)\n",
        "\n",
        "predictions = Dense(2,activation='softmax')(x)\n",
        "model = Model(inputs=inputsin, outputs=predictions)\n",
        "\n",
        "# learning rate to 0.00001\n",
        "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
        "\n",
        "# learning rate to 0.0001\n",
        "# adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "\n",
        "model.compile(optimizer = adam_optimizer, loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "print(model.metrics_names)\n",
        "print(model.summary())\n",
        "\n",
        "# early stopping\n",
        "es = EarlyStopping(monitor='val_loss', min_delta=0.01, mode='min', verbose=1, patience=25)                          #patience\n",
        "mc = ModelCheckpoint('model3flipped_acc.hdf5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)        #filepath (save model as)\n",
        "mces = ModelCheckpoint('model3flipped_loss.hdf5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)      #filepath (save model as)\n",
        "\n",
        "# fit model\n",
        "# hist=model.fit(eval_data,eval_label,validation_split=0.2,epochs=1000,batch_size=128,verbose=1,callbacks=[es, mc,mces],shuffle=False) #epochs #split #\n",
        "\n",
        "# fit model (without early stopping)\n",
        "# hist=model.fit(eval_data,eval_label,validation_split=0.2,epochs=20,batch_size=128,verbose=1,callbacks=[mc,mces],shuffle=False) #epochs #split #\n",
        "\n",
        "\n",
        "\n",
        "print('The End')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 22, 15000)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 11, 32)       960032      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 11, 32)       1920032     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 11, 32)       3840032     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 11, 32)       128         conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 11, 32)       128         conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 11, 32)       128         conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 11, 96)       0           batch_normalization[0][0]        \n",
            "                                                                 batch_normalization_1[0][0]      \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 11, 96)       0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 6, 32)        6176        dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 6, 32)        12320       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 6, 32)        24608       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 6, 32)        128         conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 6, 32)        128         conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 6, 32)        128         conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 6, 96)        0           batch_normalization_3[0][0]      \n",
            "                                                                 batch_normalization_4[0][0]      \n",
            "                                                                 batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 6, 96)        0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 3, 32)        6176        dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_7 (Conv1D)               (None, 3, 32)        12320       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_8 (Conv1D)               (None, 3, 32)        24608       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 3, 32)        128         conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 3, 32)        128         conv1d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 3, 32)        128         conv1d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 3, 96)        0           batch_normalization_6[0][0]      \n",
            "                                                                 batch_normalization_7[0][0]      \n",
            "                                                                 batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 3, 96)        0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "gru (GRU)                       (None, 3, 32)        12480       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "gru_1 (GRU)                     (None, 3, 32)        6336        gru[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 3, 64)        0           gru[0][0]                        \n",
            "                                                                 gru_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "gru_2 (GRU)                     (None, 3, 32)        9408        concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 3, 96)        0           gru[0][0]                        \n",
            "                                                                 gru_1[0][0]                      \n",
            "                                                                 gru_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "gru_3 (GRU)                     (None, 32)           12480       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 2)            66          gru_3[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 6,848,226\n",
            "Trainable params: 6,847,650\n",
            "Non-trainable params: 576\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "The End\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyrlCz0HwIs5"
      },
      "source": [
        "model.load_weights(\"model3flipped_loss.hdf5\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCnOUyKHnbuS"
      },
      "source": [
        "hist=model.fit(eval_data,eval_label,validation_data=((test_data, test_label)),epochs=20,batch_size=32,verbose=1,callbacks=[mc,mces],shuffle=False) #epochs #split #\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPBHNC1VwGBv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "KBXOFqVWYaRz",
        "outputId": "3ac9521b-d220-499e-cf29-d6eed42e865d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsKB7sTgFoj9"
      },
      "source": [
        "# 8-bit full integer quantization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ovi5gKaVj66m",
        "outputId": "f178bd60-db5f-4c58-d4e9-bb894bdbd28f"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_types = [tf.float16]\n",
        "tflite_quant_model = converter.convert()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses, gru_cell_2_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses, gru_cell_2_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpcgrrds6h/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpcgrrds6h/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVzwK605k8qX",
        "outputId": "42e80dc3-9743-4463-c740-c230684c9a79"
      },
      "source": [
        "import pathlib\n",
        "\n",
        "tflite_models_dir = pathlib.Path(\"\")\n",
        "#tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
        "'''\n",
        "# Save the unquantized/float model:\n",
        "tflite_model_file = tflite_models_dir/\"mnist_model.tflite\"\n",
        "tflite_model_file.write_bytes(tflite_model)\n",
        "'''\n",
        "# Save the quantized model:\n",
        "tflite_model_quant_file = tflite_models_dir/\"model_quant.tflite\"\n",
        "tflite_model_quant_file.write_bytes(tflite_quant_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6912384"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLGFWhYLlHoa",
        "outputId": "22f134a9-9fe3-448c-f559-69a4182ccf45"
      },
      "source": [
        "tflite_interpreter = tf.lite.Interpreter('model_quant.tflite')\n",
        "\n",
        "input_details = tflite_interpreter.get_input_details()\n",
        "output_details = tflite_interpreter.get_output_details()\n",
        "\n",
        "\n",
        "#tflite_interpreter.resize_tensor_input(input_details[0]['index'], (60, 22, 15000))\n",
        "#tflite_interpreter.resize_tensor_input(output_details[0]['index'], (60, 2))\n",
        "tflite_interpreter.allocate_tensors()\n",
        "\n",
        "\n",
        "predictions = []\n",
        "for data in test_data:\n",
        "  tflite_interpreter.set_tensor(input_details[0]['index'], [data])\n",
        "\n",
        "  tflite_interpreter.invoke()\n",
        "\n",
        "  tflite_model_predictions = tflite_interpreter.get_tensor(output_details[0]['index'])\n",
        "  print(\"Prediction results shape:\", tflite_model_predictions.shape)\n",
        "  predictions.append(tflite_model_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sL-wf17h0i3D",
        "outputId": "46be6344-df8e-4bbf-f51b-c56812fffc60"
      },
      "source": [
        "print(f'{tflite_interpreter.get_input_details()},\\n {tflite_interpreter.get_output_details()}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'name': 'serving_default_input_1:0', 'index': 0, 'shape': array([    1,    22, 15000], dtype=int32), 'shape_signature': array([   -1,    22, 15000], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}],\n",
            " [{'name': 'StatefulPartitionedCall:0', 'index': 192, 'shape': array([1, 2], dtype=int32), 'shape_signature': array([-1,  2], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QPd2-YA26ZW",
        "outputId": "35b28b70-64f3-44b2-cc98-e2d539e959b5"
      },
      "source": [
        "count = 0\n",
        "for i in range(len(predictions)):\n",
        "  if (predictions[i][0][0] > predictions[i][0][1]) and (test_label[i][0] == 1):\n",
        "    count += 1\n",
        "  elif (predictions[i][0][0] < predictions[i][0][1]) and (test_label[i][1] == 1):\n",
        "    count += 1\n",
        "print(f'total correct predictions = {count}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total correct predictions = 47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CDRrpko3WXv",
        "outputId": "43775401-9a47-4e45-bbfe-83a8062b4960"
      },
      "source": [
        "print(f'accuracy = {47/60}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy = 0.7833333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJsPigeZ7A_S",
        "outputId": "26cc3a0a-888a-4312-efe5-a9bc8fc78dff"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_types = [tf.float16]\n",
        "tflite_quant_model_f = converter.convert()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses, gru_cell_2_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses, gru_cell_2_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpcjllcxe6/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpcjllcxe6/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8rsiPd5FvZs"
      },
      "source": [
        "# 16-bit float quantization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaEIpXr6A94K",
        "outputId": "d3b7a5fc-753b-4614-c128-5fb7c6570d1c"
      },
      "source": [
        "import pathlib\n",
        "\n",
        "tflite_models_dir = pathlib.Path(\"\")\n",
        "#tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
        "'''\n",
        "# Save the unquantized/float model:\n",
        "tflite_model_file = tflite_models_dir/\"mnist_model.tflite\"\n",
        "tflite_model_file.write_bytes(tflite_model)\n",
        "'''\n",
        "# Save the quantized model:\n",
        "tflite_model_quant_file = tflite_models_dir/\"model_quant_f.tflite\"\n",
        "tflite_model_quant_file.write_bytes(tflite_quant_model_f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13754288"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7pMHIPeBv-q",
        "outputId": "d779a3f5-27d1-4359-aa88-9b60438d2d49"
      },
      "source": [
        "tflite_interpreter = tf.lite.Interpreter('model_quant_f.tflite')\n",
        "\n",
        "input_details = tflite_interpreter.get_input_details()\n",
        "output_details = tflite_interpreter.get_output_details()\n",
        "\n",
        "\n",
        "#tflite_interpreter.resize_tensor_input(input_details[0]['index'], (60, 22, 15000))\n",
        "#tflite_interpreter.resize_tensor_input(output_details[0]['index'], (60, 2))\n",
        "tflite_interpreter.allocate_tensors()\n",
        "\n",
        "\n",
        "predictions = []\n",
        "for data in test_data:\n",
        "  tflite_interpreter.set_tensor(input_details[0]['index'], [data])\n",
        "\n",
        "  tflite_interpreter.invoke()\n",
        "\n",
        "  tflite_model_predictions = tflite_interpreter.get_tensor(output_details[0]['index'])\n",
        "  print(\"Prediction results shape:\", tflite_model_predictions.shape)\n",
        "  predictions.append(tflite_model_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n",
            "Prediction results shape: (1, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3E0ssfoBJ-7",
        "outputId": "fb589a73-64c3-4b60-d465-df04ccc8178b"
      },
      "source": [
        "count = 0\n",
        "for i in range(len(predictions)):\n",
        "  if (predictions[i][0][0] > predictions[i][0][1]) and (test_label[i][0] == 1):\n",
        "    count += 1\n",
        "  elif (predictions[i][0][0] < predictions[i][0][1]) and (test_label[i][1] == 1):\n",
        "    count += 1\n",
        "print(f'total correct predictions = {count}')\n",
        "print(f'accuracy = {count/60}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total correct predictions = 47\n",
            "accuracy = 0.7833333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeKX0TtTdT7k"
      },
      "source": [
        "# Prunning 50 %"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vegc-RogBRSj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ba4cddc-4d89-49bf-bf60-7d89d5d2a825"
      },
      "source": [
        "model.load_weights(\"/content/model3flipped_loss.hdf5\")\n",
        "\n",
        "\n",
        "!pip install tensorflow_model_optimization\n",
        "is_tfmot = True\n",
        "\n",
        "\n",
        "if not(is_tfmot):\n",
        "  !pip install tensorflow_model_optimization\n",
        "  is_tfmot = True\n",
        "\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Compute end step to finish pruning after 2 epochs.\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "#validation_split = 0.1 # 10% of training set will be used for validation set. \n",
        "\n",
        "num_images = eval_data.shape[0]\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "\n",
        "# Define model for pruning.\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.20,\n",
        "                                                               final_sparsity=0.50,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step,\n",
        "                                                               frequency=5)\n",
        "}\n",
        "\n",
        "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_for_pruning.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_model_optimization in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (0.1.6)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.19.5)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.15.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 22, 15000)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d (Pru (None, 11, 32)       1920034     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_1 (P (None, 11, 32)       3840034     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_2 (P (None, 11, 32)       7680034     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 11, 32)       129         prune_low_magnitude_conv1d[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 11, 32)       129         prune_low_magnitude_conv1d_1[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 11, 32)       129         prune_low_magnitude_conv1d_2[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 11, 96)       1           prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_dropout (Pr (None, 11, 96)       1           prune_low_magnitude_concatenate[0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_3 (P (None, 6, 32)        12322       prune_low_magnitude_dropout[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_4 (P (None, 6, 32)        24610       prune_low_magnitude_dropout[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_5 (P (None, 6, 32)        49186       prune_low_magnitude_dropout[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 6, 32)        129         prune_low_magnitude_conv1d_3[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 6, 32)        129         prune_low_magnitude_conv1d_4[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 6, 32)        129         prune_low_magnitude_conv1d_5[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 6, 96)        1           prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_dropout_1 ( (None, 6, 96)        1           prune_low_magnitude_concatenate_1\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_6 (P (None, 3, 32)        12322       prune_low_magnitude_dropout_1[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_7 (P (None, 3, 32)        24610       prune_low_magnitude_dropout_1[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_8 (P (None, 3, 32)        49186       prune_low_magnitude_dropout_1[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 3, 32)        129         prune_low_magnitude_conv1d_6[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 3, 32)        129         prune_low_magnitude_conv1d_7[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 3, 32)        129         prune_low_magnitude_conv1d_8[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 3, 96)        1           prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_dropout_2 ( (None, 3, 96)        1           prune_low_magnitude_concatenate_2\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_gru (PruneL (None, 3, 32)        24771       prune_low_magnitude_dropout_2[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_gru_1 (Prun (None, 3, 32)        12483       prune_low_magnitude_gru[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 3, 64)        1           prune_low_magnitude_gru[0][0]    \n",
            "                                                                 prune_low_magnitude_gru_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_gru_2 (Prun (None, 3, 32)        18627       prune_low_magnitude_concatenate_3\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 3, 96)        1           prune_low_magnitude_gru[0][0]    \n",
            "                                                                 prune_low_magnitude_gru_1[0][0]  \n",
            "                                                                 prune_low_magnitude_gru_2[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_gru_3 (Prun (None, 32)           24771       prune_low_magnitude_concatenate_4\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_dense (Prun (None, 2)            132         prune_low_magnitude_gru_3[0][0]  \n",
            "==================================================================================================\n",
            "Total params: 13,694,291\n",
            "Trainable params: 6,847,650\n",
            "Non-trainable params: 6,846,641\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnW8kODCdjpt",
        "outputId": "c4379b18-0f5a-4234-a238-1536eaa40c51"
      },
      "source": [
        "import tempfile\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "\n",
        "hist = model_for_pruning.fit(eval_data, eval_label, validation_data=(test_data, test_label), epochs=10, batch_size=32, verbose=1, callbacks=callbacks) #epochs #split #"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "109/109 [==============================] - 109s 832ms/step - loss: 0.4189 - accuracy: 0.8130 - val_loss: 0.6937 - val_accuracy: 0.8333\n",
            "Epoch 2/10\n",
            "109/109 [==============================] - 88s 810ms/step - loss: 0.1430 - accuracy: 0.9455 - val_loss: 0.9763 - val_accuracy: 0.7833\n",
            "Epoch 3/10\n",
            "109/109 [==============================] - 88s 812ms/step - loss: 0.0907 - accuracy: 0.9656 - val_loss: 1.0731 - val_accuracy: 0.8000\n",
            "Epoch 4/10\n",
            "109/109 [==============================] - 89s 817ms/step - loss: 0.0504 - accuracy: 0.9822 - val_loss: 1.0439 - val_accuracy: 0.7833\n",
            "Epoch 5/10\n",
            "109/109 [==============================] - 89s 823ms/step - loss: 0.0397 - accuracy: 0.9850 - val_loss: 1.0517 - val_accuracy: 0.8000\n",
            "Epoch 6/10\n",
            "109/109 [==============================] - 88s 797ms/step - loss: 0.0229 - accuracy: 0.9935 - val_loss: 1.1355 - val_accuracy: 0.8167\n",
            "Epoch 7/10\n",
            "109/109 [==============================] - 87s 804ms/step - loss: 0.0203 - accuracy: 0.9925 - val_loss: 1.1853 - val_accuracy: 0.8167\n",
            "Epoch 8/10\n",
            "109/109 [==============================] - 87s 802ms/step - loss: 0.0175 - accuracy: 0.9936 - val_loss: 1.0322 - val_accuracy: 0.8167\n",
            "Epoch 9/10\n",
            "109/109 [==============================] - 88s 811ms/step - loss: 0.0202 - accuracy: 0.9934 - val_loss: 1.1334 - val_accuracy: 0.8167\n",
            "Epoch 10/10\n",
            "109/109 [==============================] - 87s 796ms/step - loss: 0.0163 - accuracy: 0.9948 - val_loss: 1.0227 - val_accuracy: 0.8500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjiHQH5Ddmd4",
        "outputId": "95adf68a-f886-4070-fd97-7d19de9dcd03"
      },
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)\n",
        "\n",
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "_, deep_pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model_for_export, deep_pruned_keras_file, include_optimizer=False)\n",
        "print('Saved pruned Keras model to:', deep_pruned_keras_file)\n",
        "\n",
        "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(\"/content/model3flipped_loss.hdf5\")))\n",
        "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(deep_pruned_keras_file)))\n",
        "\n",
        "model_for_export = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved pruned Keras model to: /tmp/tmp3ho9smo8.h5\n",
            "Size of gzipped baseline Keras model: 74336065.00 bytes\n",
            "Size of gzipped pruned Keras model: 15845107.00 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvn1U2kkoqv2"
      },
      "source": [
        "# Pruning 60%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXBCzIaZjMTW",
        "outputId": "a59230c5-34ff-4796-9a96-a4134dadf13b"
      },
      "source": [
        "model.load_weights(\"/content/model3flipped_loss.hdf5\")\n",
        "\n",
        "\n",
        "!pip install tensorflow_model_optimization\n",
        "is_tfmot = True\n",
        "\n",
        "\n",
        "if not(is_tfmot):\n",
        "  !pip install tensorflow_model_optimization\n",
        "  is_tfmot = True\n",
        "\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Compute end step to finish pruning after 2 epochs.\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "#validation_split = 0.1 # 10% of training set will be used for validation set. \n",
        "\n",
        "num_images = eval_data.shape[0]\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "\n",
        "# Define model for pruning.\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.20,\n",
        "                                                               final_sparsity=0.60,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step,\n",
        "                                                               frequency=5)\n",
        "}\n",
        "\n",
        "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_for_pruning.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_model_optimization in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (0.1.6)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.19.5)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.15.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 22, 15000)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d (Pru (None, 11, 32)       1920034     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_1 (P (None, 11, 32)       3840034     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_2 (P (None, 11, 32)       7680034     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 11, 32)       129         prune_low_magnitude_conv1d[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 11, 32)       129         prune_low_magnitude_conv1d_1[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 11, 32)       129         prune_low_magnitude_conv1d_2[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 11, 96)       1           prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_dropout (Pr (None, 11, 96)       1           prune_low_magnitude_concatenate[0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_3 (P (None, 6, 32)        12322       prune_low_magnitude_dropout[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_4 (P (None, 6, 32)        24610       prune_low_magnitude_dropout[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_5 (P (None, 6, 32)        49186       prune_low_magnitude_dropout[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 6, 32)        129         prune_low_magnitude_conv1d_3[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 6, 32)        129         prune_low_magnitude_conv1d_4[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 6, 32)        129         prune_low_magnitude_conv1d_5[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 6, 96)        1           prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_dropout_1 ( (None, 6, 96)        1           prune_low_magnitude_concatenate_1\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_6 (P (None, 3, 32)        12322       prune_low_magnitude_dropout_1[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_7 (P (None, 3, 32)        24610       prune_low_magnitude_dropout_1[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_8 (P (None, 3, 32)        49186       prune_low_magnitude_dropout_1[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 3, 32)        129         prune_low_magnitude_conv1d_6[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 3, 32)        129         prune_low_magnitude_conv1d_7[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 3, 32)        129         prune_low_magnitude_conv1d_8[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 3, 96)        1           prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_dropout_2 ( (None, 3, 96)        1           prune_low_magnitude_concatenate_2\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_gru (PruneL (None, 3, 32)        24771       prune_low_magnitude_dropout_2[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_gru_1 (Prun (None, 3, 32)        12483       prune_low_magnitude_gru[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 3, 64)        1           prune_low_magnitude_gru[0][0]    \n",
            "                                                                 prune_low_magnitude_gru_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_gru_2 (Prun (None, 3, 32)        18627       prune_low_magnitude_concatenate_3\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 3, 96)        1           prune_low_magnitude_gru[0][0]    \n",
            "                                                                 prune_low_magnitude_gru_1[0][0]  \n",
            "                                                                 prune_low_magnitude_gru_2[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_gru_3 (Prun (None, 32)           24771       prune_low_magnitude_concatenate_4\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_dense (Prun (None, 2)            132         prune_low_magnitude_gru_3[0][0]  \n",
            "==================================================================================================\n",
            "Total params: 13,694,291\n",
            "Trainable params: 6,847,650\n",
            "Non-trainable params: 6,846,641\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxRmSUNPot7v",
        "outputId": "1e1b7de5-bb87-40ce-db34-64364e79ff15"
      },
      "source": [
        "import tempfile\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "\n",
        "hist = model_for_pruning.fit(eval_data, eval_label, validation_data=(test_data, test_label), epochs=10, batch_size=32, verbose=1, callbacks=callbacks) #epochs #split #"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "109/109 [==============================] - 108s 826ms/step - loss: 0.4384 - accuracy: 0.8060 - val_loss: 0.8230 - val_accuracy: 0.7833\n",
            "Epoch 2/10\n",
            "109/109 [==============================] - 88s 810ms/step - loss: 0.1401 - accuracy: 0.9432 - val_loss: 0.8822 - val_accuracy: 0.8000\n",
            "Epoch 3/10\n",
            "109/109 [==============================] - 89s 815ms/step - loss: 0.0615 - accuracy: 0.9765 - val_loss: 1.0639 - val_accuracy: 0.8000\n",
            "Epoch 4/10\n",
            "109/109 [==============================] - 88s 813ms/step - loss: 0.0614 - accuracy: 0.9765 - val_loss: 1.2244 - val_accuracy: 0.8000\n",
            "Epoch 5/10\n",
            "109/109 [==============================] - 87s 802ms/step - loss: 0.0400 - accuracy: 0.9854 - val_loss: 1.1386 - val_accuracy: 0.8000\n",
            "Epoch 6/10\n",
            " 96/109 [=========================>....] - ETA: 10s - loss: 0.0226 - accuracy: 0.9921"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QvCzFAHoxmz",
        "outputId": "01388ad8-820d-4acb-b2f5-3f20279892eb"
      },
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)\n",
        "\n",
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "_, deep_pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model_for_export, deep_pruned_keras_file, include_optimizer=False)\n",
        "print('Saved pruned Keras model to:', deep_pruned_keras_file)\n",
        "\n",
        "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(\"/content/model3flipped_loss.hdf5\")))\n",
        "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(deep_pruned_keras_file)))\n",
        "\n",
        "model_for_export = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved pruned Keras model to: /tmp/tmpvm82skfj.h5\n",
            "Size of gzipped baseline Keras model: 74336065.00 bytes\n",
            "Size of gzipped pruned Keras model: 13465647.00 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uw0X9HEOpLZk"
      },
      "source": [
        "#Pruning 70%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BeD5LT2pKef",
        "outputId": "b846c2d1-b2e3-489a-bdc7-d4befa53121b"
      },
      "source": [
        "model.load_weights(\"/content/model3flipped_loss.hdf5\")\n",
        "\n",
        "\n",
        "!pip install tensorflow_model_optimization\n",
        "is_tfmot = True\n",
        "\n",
        "\n",
        "if not(is_tfmot):\n",
        "  !pip install tensorflow_model_optimization\n",
        "  is_tfmot = True\n",
        "\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Compute end step to finish pruning after 2 epochs.\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "#validation_split = 0.1 # 10% of training set will be used for validation set. \n",
        "\n",
        "num_images = eval_data.shape[0]\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "\n",
        "# Define model for pruning.\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.30,\n",
        "                                                               final_sparsity=0.70,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step,\n",
        "                                                               frequency=5)\n",
        "}\n",
        "\n",
        "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_for_pruning.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_model_optimization in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.15.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (0.1.6)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.19.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 22, 15000)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d (Pru (None, 11, 32)       1920034     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_1 (P (None, 11, 32)       3840034     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_2 (P (None, 11, 32)       7680034     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 11, 32)       129         prune_low_magnitude_conv1d[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 11, 32)       129         prune_low_magnitude_conv1d_1[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 11, 32)       129         prune_low_magnitude_conv1d_2[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 11, 96)       1           prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_dropout (Pr (None, 11, 96)       1           prune_low_magnitude_concatenate[0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_3 (P (None, 6, 32)        12322       prune_low_magnitude_dropout[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_4 (P (None, 6, 32)        24610       prune_low_magnitude_dropout[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_5 (P (None, 6, 32)        49186       prune_low_magnitude_dropout[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 6, 32)        129         prune_low_magnitude_conv1d_3[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 6, 32)        129         prune_low_magnitude_conv1d_4[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 6, 32)        129         prune_low_magnitude_conv1d_5[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 6, 96)        1           prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_dropout_1 ( (None, 6, 96)        1           prune_low_magnitude_concatenate_1\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_6 (P (None, 3, 32)        12322       prune_low_magnitude_dropout_1[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_7 (P (None, 3, 32)        24610       prune_low_magnitude_dropout_1[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_8 (P (None, 3, 32)        49186       prune_low_magnitude_dropout_1[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 3, 32)        129         prune_low_magnitude_conv1d_6[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 3, 32)        129         prune_low_magnitude_conv1d_7[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 3, 32)        129         prune_low_magnitude_conv1d_8[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 3, 96)        1           prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_dropout_2 ( (None, 3, 96)        1           prune_low_magnitude_concatenate_2\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_gru (PruneL (None, 3, 32)        24771       prune_low_magnitude_dropout_2[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_gru_1 (Prun (None, 3, 32)        12483       prune_low_magnitude_gru[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 3, 64)        1           prune_low_magnitude_gru[0][0]    \n",
            "                                                                 prune_low_magnitude_gru_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_gru_2 (Prun (None, 3, 32)        18627       prune_low_magnitude_concatenate_3\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 3, 96)        1           prune_low_magnitude_gru[0][0]    \n",
            "                                                                 prune_low_magnitude_gru_1[0][0]  \n",
            "                                                                 prune_low_magnitude_gru_2[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_gru_3 (Prun (None, 32)           24771       prune_low_magnitude_concatenate_4\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_dense (Prun (None, 2)            132         prune_low_magnitude_gru_3[0][0]  \n",
            "==================================================================================================\n",
            "Total params: 13,694,291\n",
            "Trainable params: 6,847,650\n",
            "Non-trainable params: 6,846,641\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0a3UYe0pSWY",
        "outputId": "c1f5e9f0-69b5-485a-ae81-673abec4d030"
      },
      "source": [
        "import tempfile\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "\n",
        "hist = model_for_pruning.fit(eval_data, eval_label, validation_data=(test_data, test_label), epochs=10, batch_size=32, verbose=1, callbacks=callbacks) #epochs #split #"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "28/28 [==============================] - 79s 2s/step - loss: 0.2902 - accuracy: 0.8979 - val_loss: 0.8308 - val_accuracy: 0.6833\n",
            "Epoch 2/10\n",
            "28/28 [==============================] - 59s 2s/step - loss: 0.1224 - accuracy: 0.9550 - val_loss: 0.7620 - val_accuracy: 0.7667\n",
            "Epoch 3/10\n",
            "28/28 [==============================] - 57s 2s/step - loss: 0.0495 - accuracy: 0.9805 - val_loss: 0.8988 - val_accuracy: 0.7667\n",
            "Epoch 4/10\n",
            "28/28 [==============================] - 58s 2s/step - loss: 0.0337 - accuracy: 0.9885 - val_loss: 1.1142 - val_accuracy: 0.7333\n",
            "Epoch 5/10\n",
            "28/28 [==============================] - 58s 2s/step - loss: 0.0158 - accuracy: 0.9953 - val_loss: 1.0788 - val_accuracy: 0.7833\n",
            "Epoch 6/10\n",
            "28/28 [==============================] - 64s 2s/step - loss: 0.0158 - accuracy: 0.9952 - val_loss: 1.3198 - val_accuracy: 0.7667\n",
            "Epoch 7/10\n",
            "28/28 [==============================] - 58s 2s/step - loss: 0.0097 - accuracy: 0.9975 - val_loss: 1.4131 - val_accuracy: 0.7500\n",
            "Epoch 8/10\n",
            "28/28 [==============================] - 57s 2s/step - loss: 0.0158 - accuracy: 0.9946 - val_loss: 1.2907 - val_accuracy: 0.8167\n",
            "Epoch 9/10\n",
            "28/28 [==============================] - 58s 2s/step - loss: 0.0242 - accuracy: 0.9925 - val_loss: 1.5710 - val_accuracy: 0.7667\n",
            "Epoch 10/10\n",
            "28/28 [==============================] - 56s 2s/step - loss: 0.0105 - accuracy: 0.9952 - val_loss: 1.3786 - val_accuracy: 0.7667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gj7jQChapUR2",
        "outputId": "8e8a6d78-40ee-4d92-8dc8-337b09f65a23"
      },
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)\n",
        "\n",
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "_, deep_pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model_for_export, deep_pruned_keras_file, include_optimizer=False)\n",
        "print('Saved pruned Keras model to:', deep_pruned_keras_file)\n",
        "\n",
        "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(\"/content/model3flipped_loss.hdf5\")))\n",
        "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(deep_pruned_keras_file)))\n",
        "\n",
        "model_for_export = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved pruned Keras model to: /tmp/tmpflwkbazw.h5\n",
            "Size of gzipped baseline Keras model: 74336065.00 bytes\n",
            "Size of gzipped pruned Keras model: 15006242.00 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRtqQbu_vgJB"
      },
      "source": [
        "# Pruning 80%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beZgrHfKpV1m",
        "outputId": "24d2030a-a8ef-4d00-90fd-5ad4893dd59d"
      },
      "source": [
        "model.load_weights(\"/content/model3flipped_loss.hdf5\")\n",
        "\n",
        "\n",
        "!pip install tensorflow_model_optimization\n",
        "is_tfmot = True\n",
        "\n",
        "\n",
        "if not(is_tfmot):\n",
        "  !pip install tensorflow_model_optimization\n",
        "  is_tfmot = True\n",
        "\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Compute end step to finish pruning after 2 epochs.\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "#validation_split = 0.1 # 10% of training set will be used for validation set. \n",
        "\n",
        "num_images = eval_data.shape[0]\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "\n",
        "# Define model for pruning.\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.30,\n",
        "                                                               final_sparsity=0.80,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step,\n",
        "                                                               frequency=5)\n",
        "}\n",
        "\n",
        "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_for_pruning.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_model_optimization in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (0.1.6)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.19.5)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.15.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 22, 15000)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_9 (P (None, 11, 32)       1920034     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_10 ( (None, 11, 32)       3840034     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_11 ( (None, 11, 32)       7680034     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 11, 32)       129         prune_low_magnitude_conv1d_9[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 11, 32)       129         prune_low_magnitude_conv1d_10[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 11, 32)       129         prune_low_magnitude_conv1d_11[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 11, 96)       1           prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_dropout_3 ( (None, 11, 96)       1           prune_low_magnitude_concatenate_5\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_12 ( (None, 6, 32)        12322       prune_low_magnitude_dropout_3[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_13 ( (None, 6, 32)        24610       prune_low_magnitude_dropout_3[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_14 ( (None, 6, 32)        49186       prune_low_magnitude_dropout_3[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 6, 32)        129         prune_low_magnitude_conv1d_12[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 6, 32)        129         prune_low_magnitude_conv1d_13[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 6, 32)        129         prune_low_magnitude_conv1d_14[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 6, 96)        1           prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_dropout_4 ( (None, 6, 96)        1           prune_low_magnitude_concatenate_6\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_15 ( (None, 3, 32)        12322       prune_low_magnitude_dropout_4[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_16 ( (None, 3, 32)        24610       prune_low_magnitude_dropout_4[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_17 ( (None, 3, 32)        49186       prune_low_magnitude_dropout_4[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 3, 32)        129         prune_low_magnitude_conv1d_15[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 3, 32)        129         prune_low_magnitude_conv1d_16[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 3, 32)        129         prune_low_magnitude_conv1d_17[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 3, 96)        1           prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_dropout_5 ( (None, 3, 96)        1           prune_low_magnitude_concatenate_7\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_gru_4 (Prun (None, 3, 32)        24771       prune_low_magnitude_dropout_5[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_gru_5 (Prun (None, 3, 32)        12483       prune_low_magnitude_gru_4[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 3, 64)        1           prune_low_magnitude_gru_4[0][0]  \n",
            "                                                                 prune_low_magnitude_gru_5[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_gru_6 (Prun (None, 3, 32)        18627       prune_low_magnitude_concatenate_8\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 3, 96)        1           prune_low_magnitude_gru_4[0][0]  \n",
            "                                                                 prune_low_magnitude_gru_5[0][0]  \n",
            "                                                                 prune_low_magnitude_gru_6[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_gru_7 (Prun (None, 32)           24771       prune_low_magnitude_concatenate_9\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_dense_1 (Pr (None, 2)            132         prune_low_magnitude_gru_7[0][0]  \n",
            "==================================================================================================\n",
            "Total params: 13,694,291\n",
            "Trainable params: 6,847,650\n",
            "Non-trainable params: 6,846,641\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Lmm6zRhviCp",
        "outputId": "812bec8d-6ef6-4f81-e245-7089ac804ca0"
      },
      "source": [
        "import tempfile\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "\n",
        "hist = model_for_pruning.fit(eval_data, eval_label, validation_data=(test_data, test_label), epochs=10, batch_size=32, verbose=1, callbacks=callbacks) #epochs #split #"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "109/109 [==============================] - 105s 802ms/step - loss: 0.3999 - accuracy: 0.8177 - val_loss: 0.6642 - val_accuracy: 0.8333\n",
            "Epoch 2/10\n",
            "109/109 [==============================] - 84s 770ms/step - loss: 0.1299 - accuracy: 0.9552 - val_loss: 0.9736 - val_accuracy: 0.7833\n",
            "Epoch 3/10\n",
            "109/109 [==============================] - 84s 769ms/step - loss: 0.0681 - accuracy: 0.9735 - val_loss: 0.9054 - val_accuracy: 0.8000\n",
            "Epoch 4/10\n",
            "109/109 [==============================] - 83s 768ms/step - loss: 0.0558 - accuracy: 0.9807 - val_loss: 0.8396 - val_accuracy: 0.8167\n",
            "Epoch 5/10\n",
            "109/109 [==============================] - 82s 754ms/step - loss: 0.0494 - accuracy: 0.9853 - val_loss: 1.0173 - val_accuracy: 0.8000\n",
            "Epoch 6/10\n",
            "109/109 [==============================] - 82s 746ms/step - loss: 0.0322 - accuracy: 0.9889 - val_loss: 1.0428 - val_accuracy: 0.8000\n",
            "Epoch 7/10\n",
            "109/109 [==============================] - 83s 765ms/step - loss: 0.0200 - accuracy: 0.9940 - val_loss: 1.0559 - val_accuracy: 0.8000\n",
            "Epoch 8/10\n",
            "109/109 [==============================] - 82s 757ms/step - loss: 0.0219 - accuracy: 0.9948 - val_loss: 1.0319 - val_accuracy: 0.8167\n",
            "Epoch 9/10\n",
            "109/109 [==============================] - 82s 752ms/step - loss: 0.0227 - accuracy: 0.9932 - val_loss: 1.0879 - val_accuracy: 0.8000\n",
            "Epoch 10/10\n",
            "109/109 [==============================] - 81s 748ms/step - loss: 0.0195 - accuracy: 0.9916 - val_loss: 1.0625 - val_accuracy: 0.8000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cItvWJO2vj89",
        "outputId": "17545daf-3c4d-4794-8ba3-f88e79b53a27"
      },
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)\n",
        "\n",
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "_, deep_pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model_for_export, deep_pruned_keras_file, include_optimizer=False)\n",
        "print('Saved pruned Keras model to:', deep_pruned_keras_file)\n",
        "\n",
        "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(\"/content/model3flipped_loss.hdf5\")))\n",
        "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(deep_pruned_keras_file)))\n",
        "\n",
        "model_for_export = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved pruned Keras model to: /tmp/tmpbzn2ness.h5\n",
            "Size of gzipped baseline Keras model: 74336065.00 bytes\n",
            "Size of gzipped pruned Keras model: 8260274.00 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wwx1DUB1zFSs"
      },
      "source": [
        "# Prunning 90%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcKKC9iavq-H",
        "outputId": "ce46f6da-8f89-4f74-e281-8378bc543311"
      },
      "source": [
        "model.load_weights(\"/content/model3flipped_loss.hdf5\")\n",
        "\n",
        "\n",
        "!pip install tensorflow_model_optimization\n",
        "is_tfmot = True\n",
        "\n",
        "\n",
        "if not(is_tfmot):\n",
        "  !pip install tensorflow_model_optimization\n",
        "  is_tfmot = True\n",
        "\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Compute end step to finish pruning after 2 epochs.\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "#validation_split = 0.1 # 10% of training set will be used for validation set. \n",
        "\n",
        "num_images = eval_data.shape[0]\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "\n",
        "# Define model for pruning.\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.30,\n",
        "                                                               final_sparsity=0.90,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step,\n",
        "                                                               frequency=5)\n",
        "}\n",
        "\n",
        "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_for_pruning.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_model_optimization in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.15.0)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.19.5)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (0.1.6)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 22, 15000)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d (Pru (None, 11, 32)       1920034     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_1 (P (None, 11, 32)       3840034     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_2 (P (None, 11, 32)       7680034     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 11, 32)       129         prune_low_magnitude_conv1d[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 11, 32)       129         prune_low_magnitude_conv1d_1[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 11, 32)       129         prune_low_magnitude_conv1d_2[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 11, 96)       1           prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_dropout (Pr (None, 11, 96)       1           prune_low_magnitude_concatenate[0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_3 (P (None, 6, 32)        12322       prune_low_magnitude_dropout[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_4 (P (None, 6, 32)        24610       prune_low_magnitude_dropout[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_5 (P (None, 6, 32)        49186       prune_low_magnitude_dropout[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 6, 32)        129         prune_low_magnitude_conv1d_3[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 6, 32)        129         prune_low_magnitude_conv1d_4[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 6, 32)        129         prune_low_magnitude_conv1d_5[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 6, 96)        1           prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_dropout_1 ( (None, 6, 96)        1           prune_low_magnitude_concatenate_1\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_6 (P (None, 3, 32)        12322       prune_low_magnitude_dropout_1[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_7 (P (None, 3, 32)        24610       prune_low_magnitude_dropout_1[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_8 (P (None, 3, 32)        49186       prune_low_magnitude_dropout_1[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 3, 32)        129         prune_low_magnitude_conv1d_6[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 3, 32)        129         prune_low_magnitude_conv1d_7[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 3, 32)        129         prune_low_magnitude_conv1d_8[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 3, 96)        1           prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_dropout_2 ( (None, 3, 96)        1           prune_low_magnitude_concatenate_2\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_gru (PruneL (None, 3, 32)        24771       prune_low_magnitude_dropout_2[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_gru_1 (Prun (None, 3, 32)        12483       prune_low_magnitude_gru[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 3, 64)        1           prune_low_magnitude_gru[0][0]    \n",
            "                                                                 prune_low_magnitude_gru_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_gru_2 (Prun (None, 3, 32)        18627       prune_low_magnitude_concatenate_3\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 3, 96)        1           prune_low_magnitude_gru[0][0]    \n",
            "                                                                 prune_low_magnitude_gru_1[0][0]  \n",
            "                                                                 prune_low_magnitude_gru_2[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_gru_3 (Prun (None, 32)           24771       prune_low_magnitude_concatenate_4\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_dense (Prun (None, 2)            132         prune_low_magnitude_gru_3[0][0]  \n",
            "==================================================================================================\n",
            "Total params: 13,694,291\n",
            "Trainable params: 6,847,650\n",
            "Non-trainable params: 6,846,641\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jrfl0k6izMjg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42b445d5-9e5e-4050-e284-0febe1339929"
      },
      "source": [
        "import tempfile\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "\n",
        "hist = model_for_pruning.fit(eval_data, eval_label, validation_data=(test_data, test_label), epochs=10, batch_size=32, verbose=1, callbacks=callbacks) #epochs #split #"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "109/109 [==============================] - 106s 804ms/step - loss: 0.4058 - accuracy: 0.8233 - val_loss: 0.7907 - val_accuracy: 0.8000\n",
            "Epoch 2/10\n",
            "109/109 [==============================] - 88s 809ms/step - loss: 0.1173 - accuracy: 0.9525 - val_loss: 0.8618 - val_accuracy: 0.8333\n",
            "Epoch 3/10\n",
            "109/109 [==============================] - 89s 815ms/step - loss: 0.0687 - accuracy: 0.9803 - val_loss: 0.8137 - val_accuracy: 0.8000\n",
            "Epoch 4/10\n",
            "109/109 [==============================] - 88s 813ms/step - loss: 0.0546 - accuracy: 0.9801 - val_loss: 0.9420 - val_accuracy: 0.7500\n",
            "Epoch 5/10\n",
            "109/109 [==============================] - 87s 803ms/step - loss: 0.0364 - accuracy: 0.9894 - val_loss: 0.8561 - val_accuracy: 0.8000\n",
            "Epoch 6/10\n",
            "109/109 [==============================] - 88s 807ms/step - loss: 0.0402 - accuracy: 0.9900 - val_loss: 0.9093 - val_accuracy: 0.7667\n",
            "Epoch 7/10\n",
            "109/109 [==============================] - 89s 822ms/step - loss: 0.0329 - accuracy: 0.9922 - val_loss: 0.7310 - val_accuracy: 0.7833\n",
            "Epoch 8/10\n",
            "109/109 [==============================] - 90s 829ms/step - loss: 0.0332 - accuracy: 0.9921 - val_loss: 0.8395 - val_accuracy: 0.8167\n",
            "Epoch 9/10\n",
            "109/109 [==============================] - 91s 840ms/step - loss: 0.0283 - accuracy: 0.9908 - val_loss: 0.8071 - val_accuracy: 0.8000\n",
            "Epoch 10/10\n",
            "109/109 [==============================] - 89s 816ms/step - loss: 0.0313 - accuracy: 0.9922 - val_loss: 0.8841 - val_accuracy: 0.8000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-GVObj0zOUe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbf01e9d-f977-4264-9979-f7ffd5f6b9fe"
      },
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)\n",
        "\n",
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "_, deep_pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model_for_export, deep_pruned_keras_file, include_optimizer=False)\n",
        "print('Saved pruned Keras model to:', deep_pruned_keras_file)\n",
        "\n",
        "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(\"/content/model3flipped_loss.hdf5\")))\n",
        "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(deep_pruned_keras_file)))\n",
        "\n",
        "model_for_export = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved pruned Keras model to: /tmp/tmphv8zmhqa.h5\n",
            "Size of gzipped baseline Keras model: 74336065.00 bytes\n",
            "Size of gzipped pruned Keras model: 5334700.00 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiVII0dszTuZ"
      },
      "source": [
        "# Pruning 95%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1xhryoYzRz-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84664a48-4f99-490c-cd98-b1108ecaaa30"
      },
      "source": [
        "model.load_weights(\"/content/model3flipped_loss.hdf5\")\n",
        "\n",
        "\n",
        "!pip install tensorflow_model_optimization\n",
        "is_tfmot = True\n",
        "\n",
        "\n",
        "if not(is_tfmot):\n",
        "  !pip install tensorflow_model_optimization\n",
        "  is_tfmot = True\n",
        "\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Compute end step to finish pruning after 2 epochs.\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "#validation_split = 0.1 # 10% of training set will be used for validation set. \n",
        "\n",
        "num_images = eval_data.shape[0]\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "\n",
        "# Define model for pruning.\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.30,\n",
        "                                                               final_sparsity=0.95,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step,\n",
        "                                                               frequency=5)\n",
        "}\n",
        "\n",
        "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_for_pruning.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_model_optimization in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.15.0)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.19.5)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (0.1.6)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 22, 15000)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d (Pru (None, 11, 32)       1920034     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_1 (P (None, 11, 32)       3840034     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_2 (P (None, 11, 32)       7680034     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 11, 32)       129         prune_low_magnitude_conv1d[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 11, 32)       129         prune_low_magnitude_conv1d_1[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 11, 32)       129         prune_low_magnitude_conv1d_2[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 11, 96)       1           prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_dropout (Pr (None, 11, 96)       1           prune_low_magnitude_concatenate[0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_3 (P (None, 6, 32)        12322       prune_low_magnitude_dropout[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_4 (P (None, 6, 32)        24610       prune_low_magnitude_dropout[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_5 (P (None, 6, 32)        49186       prune_low_magnitude_dropout[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 6, 32)        129         prune_low_magnitude_conv1d_3[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 6, 32)        129         prune_low_magnitude_conv1d_4[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 6, 32)        129         prune_low_magnitude_conv1d_5[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 6, 96)        1           prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_dropout_1 ( (None, 6, 96)        1           prune_low_magnitude_concatenate_1\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_6 (P (None, 3, 32)        12322       prune_low_magnitude_dropout_1[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_7 (P (None, 3, 32)        24610       prune_low_magnitude_dropout_1[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_8 (P (None, 3, 32)        49186       prune_low_magnitude_dropout_1[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 3, 32)        129         prune_low_magnitude_conv1d_6[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 3, 32)        129         prune_low_magnitude_conv1d_7[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 3, 32)        129         prune_low_magnitude_conv1d_8[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 3, 96)        1           prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_dropout_2 ( (None, 3, 96)        1           prune_low_magnitude_concatenate_2\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_gru (PruneL (None, 3, 32)        24771       prune_low_magnitude_dropout_2[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_gru_1 (Prun (None, 3, 32)        12483       prune_low_magnitude_gru[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 3, 64)        1           prune_low_magnitude_gru[0][0]    \n",
            "                                                                 prune_low_magnitude_gru_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_gru_2 (Prun (None, 3, 32)        18627       prune_low_magnitude_concatenate_3\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 3, 96)        1           prune_low_magnitude_gru[0][0]    \n",
            "                                                                 prune_low_magnitude_gru_1[0][0]  \n",
            "                                                                 prune_low_magnitude_gru_2[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_gru_3 (Prun (None, 32)           24771       prune_low_magnitude_concatenate_4\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_dense (Prun (None, 2)            132         prune_low_magnitude_gru_3[0][0]  \n",
            "==================================================================================================\n",
            "Total params: 13,694,291\n",
            "Trainable params: 6,847,650\n",
            "Non-trainable params: 6,846,641\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oyo2CgmzXAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bd0e763-225c-4535-cbb2-7d80aabe1191"
      },
      "source": [
        "import tempfile\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "\n",
        "hist = model_for_pruning.fit(eval_data, eval_label, validation_data=(test_data, test_label), epochs=30, batch_size=128, verbose=1, callbacks=callbacks) #epochs #split #"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "28/28 [==============================] - 81s 2s/step - loss: 0.2951 - accuracy: 0.8915 - val_loss: 0.8001 - val_accuracy: 0.7000\n",
            "Epoch 2/30\n",
            "28/28 [==============================] - 62s 2s/step - loss: 0.1260 - accuracy: 0.9522 - val_loss: 0.9935 - val_accuracy: 0.7500\n",
            "Epoch 3/30\n",
            "28/28 [==============================] - 61s 2s/step - loss: 0.0429 - accuracy: 0.9830 - val_loss: 1.1727 - val_accuracy: 0.7667\n",
            "Epoch 4/30\n",
            "28/28 [==============================] - 62s 2s/step - loss: 0.0246 - accuracy: 0.9928 - val_loss: 1.1079 - val_accuracy: 0.8167\n",
            "Epoch 5/30\n",
            "28/28 [==============================] - 62s 2s/step - loss: 0.0188 - accuracy: 0.9931 - val_loss: 0.9959 - val_accuracy: 0.8167\n",
            "Epoch 6/30\n",
            "28/28 [==============================] - 62s 2s/step - loss: 0.0212 - accuracy: 0.9920 - val_loss: 1.1367 - val_accuracy: 0.7667\n",
            "Epoch 7/30\n",
            "28/28 [==============================] - 64s 2s/step - loss: 0.0264 - accuracy: 0.9919 - val_loss: 1.0982 - val_accuracy: 0.7833\n",
            "Epoch 8/30\n",
            "28/28 [==============================] - 61s 2s/step - loss: 0.0176 - accuracy: 0.9943 - val_loss: 1.3083 - val_accuracy: 0.7667\n",
            "Epoch 9/30\n",
            "28/28 [==============================] - 63s 2s/step - loss: 0.0177 - accuracy: 0.9953 - val_loss: 1.2966 - val_accuracy: 0.8000\n",
            "Epoch 10/30\n",
            "28/28 [==============================] - 62s 2s/step - loss: 0.0089 - accuracy: 0.9964 - val_loss: 1.2623 - val_accuracy: 0.8167\n",
            "Epoch 11/30\n",
            "28/28 [==============================] - 62s 2s/step - loss: 0.0215 - accuracy: 0.9925 - val_loss: 1.1693 - val_accuracy: 0.8000\n",
            "Epoch 12/30\n",
            "28/28 [==============================] - 64s 2s/step - loss: 0.0185 - accuracy: 0.9950 - val_loss: 1.0702 - val_accuracy: 0.8167\n",
            "Epoch 13/30\n",
            "28/28 [==============================] - 62s 2s/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 1.0950 - val_accuracy: 0.8167\n",
            "Epoch 14/30\n",
            "28/28 [==============================] - 64s 2s/step - loss: 0.0194 - accuracy: 0.9933 - val_loss: 1.0229 - val_accuracy: 0.8000\n",
            "Epoch 15/30\n",
            "28/28 [==============================] - 61s 2s/step - loss: 0.0171 - accuracy: 0.9936 - val_loss: 1.0002 - val_accuracy: 0.8167\n",
            "Epoch 16/30\n",
            "28/28 [==============================] - 63s 2s/step - loss: 0.0158 - accuracy: 0.9958 - val_loss: 0.9676 - val_accuracy: 0.8167\n",
            "Epoch 17/30\n",
            "28/28 [==============================] - 63s 2s/step - loss: 0.0091 - accuracy: 0.9987 - val_loss: 0.9554 - val_accuracy: 0.8333\n",
            "Epoch 18/30\n",
            "28/28 [==============================] - 62s 2s/step - loss: 0.0131 - accuracy: 0.9973 - val_loss: 0.9223 - val_accuracy: 0.8000\n",
            "Epoch 19/30\n",
            "28/28 [==============================] - 64s 2s/step - loss: 0.0126 - accuracy: 0.9981 - val_loss: 0.9297 - val_accuracy: 0.8000\n",
            "Epoch 20/30\n",
            "28/28 [==============================] - 62s 2s/step - loss: 0.0122 - accuracy: 0.9982 - val_loss: 0.8954 - val_accuracy: 0.8167\n",
            "Epoch 21/30\n",
            "28/28 [==============================] - 63s 2s/step - loss: 0.0171 - accuracy: 0.9946 - val_loss: 0.8228 - val_accuracy: 0.8167\n",
            "Epoch 22/30\n",
            "28/28 [==============================] - 64s 2s/step - loss: 0.0120 - accuracy: 0.9995 - val_loss: 0.9660 - val_accuracy: 0.7833\n",
            "Epoch 23/30\n",
            "28/28 [==============================] - 61s 2s/step - loss: 0.0115 - accuracy: 0.9992 - val_loss: 0.8605 - val_accuracy: 0.8000\n",
            "Epoch 24/30\n",
            "28/28 [==============================] - 64s 2s/step - loss: 0.0105 - accuracy: 0.9997 - val_loss: 0.9159 - val_accuracy: 0.8000\n",
            "Epoch 25/30\n",
            "28/28 [==============================] - 62s 2s/step - loss: 0.0190 - accuracy: 0.9976 - val_loss: 0.8462 - val_accuracy: 0.8167\n",
            "Epoch 26/30\n",
            "28/28 [==============================] - 64s 2s/step - loss: 0.0166 - accuracy: 0.9979 - val_loss: 0.8833 - val_accuracy: 0.8167\n",
            "Epoch 27/30\n",
            "28/28 [==============================] - 64s 2s/step - loss: 0.0126 - accuracy: 0.9987 - val_loss: 0.7551 - val_accuracy: 0.8167\n",
            "Epoch 28/30\n",
            "28/28 [==============================] - 63s 2s/step - loss: 0.0212 - accuracy: 0.9986 - val_loss: 0.8674 - val_accuracy: 0.7833\n",
            "Epoch 29/30\n",
            "28/28 [==============================] - 65s 2s/step - loss: 0.0161 - accuracy: 0.9981 - val_loss: 0.9377 - val_accuracy: 0.7833\n",
            "Epoch 30/30\n",
            "28/28 [==============================] - 61s 2s/step - loss: 0.0159 - accuracy: 0.9981 - val_loss: 1.0237 - val_accuracy: 0.7667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT9IpzZhzaTJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "935bab88-8a11-4c4f-a8bf-f293c72ff198"
      },
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)\n",
        "\n",
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "_, deep_pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model_for_export, deep_pruned_keras_file, include_optimizer=False)\n",
        "print('Saved pruned Keras model to:', deep_pruned_keras_file)\n",
        "\n",
        "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(\"/content/model3flipped_loss.hdf5\")))\n",
        "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(deep_pruned_keras_file)))\n",
        "\n",
        "model_for_export = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved pruned Keras model to: /tmp/tmpynzzv4lz.h5\n",
            "Size of gzipped baseline Keras model: 74336065.00 bytes\n",
            "Size of gzipped pruned Keras model: 4010207.00 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXE8ggDOzcOA"
      },
      "source": [
        "# Prunning 99%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ymqwyxrtzbs_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba5e0559-0996-48b9-d1d9-44a956512e4b"
      },
      "source": [
        "model.load_weights(\"/content/model3flipped_loss.hdf5\")\n",
        "\n",
        "\n",
        "!pip install tensorflow_model_optimization\n",
        "is_tfmot = True\n",
        "\n",
        "model_for_export = 0\n",
        "\n",
        "\n",
        "if not(is_tfmot):\n",
        "  !pip install tensorflow_model_optimization\n",
        "  is_tfmot = True\n",
        "\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Compute end step to finish pruning after 2 epochs.\n",
        "batch_size = 32\n",
        "epochs = 20\n",
        "#validation_split = 0.1 # 10% of training set will be used for validation set. \n",
        "\n",
        "num_images = eval_data.shape[0]\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "\n",
        "# Define model for pruning.\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.30,\n",
        "                                                               final_sparsity=0.99,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step,\n",
        "                                                               frequency=5)\n",
        "}\n",
        "\n",
        "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_for_pruning.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_model_optimization in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (0.1.6)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.19.5)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.15.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 22, 15000)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d (Pru (None, 11, 32)       1920034     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_1 (P (None, 11, 32)       3840034     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_2 (P (None, 11, 32)       7680034     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 11, 32)       129         prune_low_magnitude_conv1d[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 11, 32)       129         prune_low_magnitude_conv1d_1[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 11, 32)       129         prune_low_magnitude_conv1d_2[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 11, 96)       1           prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_dropout (Pr (None, 11, 96)       1           prune_low_magnitude_concatenate[0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_3 (P (None, 6, 32)        12322       prune_low_magnitude_dropout[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_4 (P (None, 6, 32)        24610       prune_low_magnitude_dropout[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_5 (P (None, 6, 32)        49186       prune_low_magnitude_dropout[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 6, 32)        129         prune_low_magnitude_conv1d_3[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 6, 32)        129         prune_low_magnitude_conv1d_4[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 6, 32)        129         prune_low_magnitude_conv1d_5[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 6, 96)        1           prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_dropout_1 ( (None, 6, 96)        1           prune_low_magnitude_concatenate_1\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_6 (P (None, 3, 32)        12322       prune_low_magnitude_dropout_1[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_7 (P (None, 3, 32)        24610       prune_low_magnitude_dropout_1[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv1d_8 (P (None, 3, 32)        49186       prune_low_magnitude_dropout_1[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 3, 32)        129         prune_low_magnitude_conv1d_6[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 3, 32)        129         prune_low_magnitude_conv1d_7[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 3, 32)        129         prune_low_magnitude_conv1d_8[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 3, 96)        1           prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "                                                                 prune_low_magnitude_batch_normali\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_dropout_2 ( (None, 3, 96)        1           prune_low_magnitude_concatenate_2\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_gru (PruneL (None, 3, 32)        24771       prune_low_magnitude_dropout_2[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_gru_1 (Prun (None, 3, 32)        12483       prune_low_magnitude_gru[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 3, 64)        1           prune_low_magnitude_gru[0][0]    \n",
            "                                                                 prune_low_magnitude_gru_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_gru_2 (Prun (None, 3, 32)        18627       prune_low_magnitude_concatenate_3\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 3, 96)        1           prune_low_magnitude_gru[0][0]    \n",
            "                                                                 prune_low_magnitude_gru_1[0][0]  \n",
            "                                                                 prune_low_magnitude_gru_2[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_gru_3 (Prun (None, 32)           24771       prune_low_magnitude_concatenate_4\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_dense (Prun (None, 2)            132         prune_low_magnitude_gru_3[0][0]  \n",
            "==================================================================================================\n",
            "Total params: 13,694,291\n",
            "Trainable params: 6,847,650\n",
            "Non-trainable params: 6,846,641\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T950A10Ezf9Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d9ff54f-6290-4947-921c-3adc7037b04d"
      },
      "source": [
        "import tempfile\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "\n",
        "hist = model_for_pruning.fit(eval_data, eval_label, validation_data=(test_data, test_label), epochs=20, batch_size=32, verbose=1, callbacks=callbacks) #epochs #split #"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "109/109 [==============================] - 110s 847ms/step - loss: 0.3891 - accuracy: 0.8360 - val_loss: 0.6476 - val_accuracy: 0.7667\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 89s 814ms/step - loss: 0.1284 - accuracy: 0.9539 - val_loss: 0.8502 - val_accuracy: 0.8167\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 88s 808ms/step - loss: 0.0764 - accuracy: 0.9754 - val_loss: 0.9304 - val_accuracy: 0.8000\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 87s 801ms/step - loss: 0.0386 - accuracy: 0.9867 - val_loss: 1.0117 - val_accuracy: 0.8000\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 86s 788ms/step - loss: 0.0459 - accuracy: 0.9864 - val_loss: 1.0018 - val_accuracy: 0.7833\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 86s 788ms/step - loss: 0.0530 - accuracy: 0.9832 - val_loss: 0.8820 - val_accuracy: 0.8000\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 87s 805ms/step - loss: 0.0332 - accuracy: 0.9894 - val_loss: 0.9780 - val_accuracy: 0.7833\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 88s 809ms/step - loss: 0.0238 - accuracy: 0.9928 - val_loss: 0.8693 - val_accuracy: 0.8000\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 88s 806ms/step - loss: 0.0351 - accuracy: 0.9902 - val_loss: 0.7677 - val_accuracy: 0.8167\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 86s 791ms/step - loss: 0.0302 - accuracy: 0.9917 - val_loss: 0.7773 - val_accuracy: 0.7833\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 87s 792ms/step - loss: 0.0387 - accuracy: 0.9885 - val_loss: 0.7789 - val_accuracy: 0.8000\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 87s 804ms/step - loss: 0.0383 - accuracy: 0.9897 - val_loss: 0.6181 - val_accuracy: 0.8000\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 88s 810ms/step - loss: 0.0586 - accuracy: 0.9885 - val_loss: 0.7683 - val_accuracy: 0.7833\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 88s 814ms/step - loss: 0.0716 - accuracy: 0.9901 - val_loss: 0.6709 - val_accuracy: 0.8000\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 87s 798ms/step - loss: 0.0869 - accuracy: 0.9844 - val_loss: 0.5307 - val_accuracy: 0.7833\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 87s 792ms/step - loss: 0.1711 - accuracy: 0.9810 - val_loss: 0.5291 - val_accuracy: 0.8000\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 92s 850ms/step - loss: 0.1547 - accuracy: 0.9772 - val_loss: 0.5877 - val_accuracy: 0.7667\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 88s 813ms/step - loss: 0.1499 - accuracy: 0.9719 - val_loss: 0.5701 - val_accuracy: 0.7833\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 88s 813ms/step - loss: 0.1508 - accuracy: 0.9618 - val_loss: 0.6002 - val_accuracy: 0.7833\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 87s 802ms/step - loss: 0.1250 - accuracy: 0.9720 - val_loss: 0.6154 - val_accuracy: 0.7833\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0uMgmdBziZb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0920ea49-0056-4840-e078-361d5961d90b"
      },
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)\n",
        "\n",
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "_, deep_pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model_for_export, deep_pruned_keras_file, include_optimizer=False)\n",
        "print('Saved pruned Keras model to:', deep_pruned_keras_file)\n",
        "\n",
        "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(\"/content/model3flipped_loss.hdf5\")))\n",
        "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(deep_pruned_keras_file)))\n",
        "\n",
        "model_for_export = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved pruned Keras model to: /tmp/tmpyym8ctwc.h5\n",
            "Size of gzipped baseline Keras model: 74336065.00 bytes\n",
            "Size of gzipped pruned Keras model: 2295545.00 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78u3Kv1Wzjj7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}