{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ShallowNet-Simple.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AavSj7TGVKoI"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "eval_data_original = np.load(\"/content/drive/MyDrive/Colab Notebooks/eval_data_complete.npy\")\n",
        "eval_label_original = np.load(\"/content/drive/MyDrive/Colab Notebooks/eval_label_complete.npy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLrKtu7vV6Xf"
      },
      "source": [
        "eval_data = eval_data_original[10:-50]\n",
        "eval_label = eval_label_original[10:-50]\n",
        "\n",
        "test_data = np.concatenate((eval_data_original[:10], eval_data_original[-50:]))\n",
        "test_label = np.concatenate((eval_label_original[:10], eval_label_original[-50:]))\n",
        "\n",
        "eval_data_original = 0\n",
        "eval_label_original = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zQnoselWr4Z",
        "outputId": "701f152f-e0c7-4af6-8b64-e2f779b999f4"
      },
      "source": [
        "eval_data = np.concatenate((eval_data[:337], eval_data[:337], eval_data[:337], eval_data[:337], eval_data))\n",
        "eval_label = np.concatenate((eval_label[:337], eval_label[:337], eval_label[:337], eval_label[:337], eval_label))\n",
        "print(eval_data.shape)\n",
        "print(eval_label.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3483, 22, 15000)\n",
            "(3483,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUYqXdEIW2QA"
      },
      "source": [
        "idx = np.random.permutation(len(eval_data))\n",
        "eval_data,eval_label = eval_data[idx], eval_label[idx]\n",
        "eval_data = eval_data[:int(len(eval_data)/2)]\n",
        "eval_label = eval_label[:int(len(eval_label)/2)]\n",
        "idx = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBFvYqc8W8WA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f455505-0817-4dd9-b5be-1c93e13cf6e3"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "enc_labels = to_categorical(eval_label, num_classes=2)              \n",
        "test_label = to_categorical(test_label, num_classes=2)              \n",
        "eval_label= enc_labels\n",
        "enc_labels = 0\n",
        "print(eval_data.shape)\n",
        "print(eval_label.shape)\n",
        "print(eval_data.dtype)\n",
        "print(eval_label.dtype)\n",
        "print('training labels have been loaded')\n",
        "\n",
        "bs,t,f = eval_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1741, 22, 15000)\n",
            "(1741, 2)\n",
            "float32\n",
            "float32\n",
            "training labels have been loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ape2qQpRXH3p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "081dbd45-cc11-48fa-af01-465e76179754"
      },
      "source": [
        "from pdb import set_trace\n",
        "#import mne\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import os\n",
        "import h5py\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN,LSTM, Dense, Activation, Bidirectional\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Convolution2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import MaxPooling1D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import MaxPooling3D\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "# ----------------------SHALLOW-NET Testing-----------------------\n",
        "from tensorflow.keras.layers import Input,Dense,concatenate,Flatten,GRU,Conv1D,Conv2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "inputsin= Input(shape=(t,f))\n",
        "\n",
        "\n",
        "# ------------------First Inception\n",
        "shallow_net = Conv1D(40, 25, strides=1, activation='relu',padding=\"causal\")(inputsin)\n",
        "shallow_net = Flatten()(shallow_net)\n",
        "predictions = Dense(2,activation='softmax')(shallow_net)\n",
        "\n",
        "\n",
        "shallow_model = Model(inputs=inputsin, outputs=predictions)\n",
        "\n",
        "\n",
        "# learning rate to 0.00001\n",
        "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
        "\n",
        "shallow_model.compile(optimizer = adam_optimizer, loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "print(shallow_model.metrics_names)\n",
        "print(shallow_model.summary())\n",
        "\n",
        "# early stopping\n",
        "es = EarlyStopping(monitor='val_loss', min_delta=0.01, mode='min', verbose=1, patience=25)                          #patience\n",
        "mc = ModelCheckpoint('shallow_model3flipped_acc.hdf5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)        #filepath (save model as)\n",
        "mces = ModelCheckpoint('shallow_model3flipped_loss.hdf5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)      #filepath (save model as)\n",
        "\n",
        "# fit model\n",
        "# hist=shallow_model.fit(eval_data,eval_label,validation_split=0.2,epochs=10,batch_size=128,verbose=1,callbacks=[es, mc,mces],shuffle=True) #epochs #split #\n",
        "print('The End')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 22, 15000)]       0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 22, 40)            15000040  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 880)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 1762      \n",
            "=================================================================\n",
            "Total params: 15,001,802\n",
            "Trainable params: 15,001,802\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "The End\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jM0LyWlFphvQ",
        "outputId": "fd1f6f63-ab7a-49ef-c42d-29251e208a47"
      },
      "source": [
        "\n",
        "hist=shallow_model.fit(eval_data,eval_label,validation_data=(test_data, test_label),epochs=10,batch_size=32,verbose=1,callbacks=[es, mc,mces],shuffle=True) #epochs #split #\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "55/55 [==============================] - 37s 83ms/step - loss: 0.6631 - accuracy: 0.5738 - val_loss: 0.7214 - val_accuracy: 0.5667\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.72137, saving model to shallow_model3flipped_loss.hdf5\n",
            "Epoch 2/10\n",
            "55/55 [==============================] - 3s 59ms/step - loss: 0.2059 - accuracy: 0.9741 - val_loss: 0.6911 - val_accuracy: 0.5500\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.72137 to 0.69109, saving model to shallow_model3flipped_loss.hdf5\n",
            "Epoch 3/10\n",
            "55/55 [==============================] - 3s 60ms/step - loss: 0.1212 - accuracy: 0.9980 - val_loss: 0.6754 - val_accuracy: 0.6000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.69109 to 0.67536, saving model to shallow_model3flipped_loss.hdf5\n",
            "Epoch 4/10\n",
            "55/55 [==============================] - 3s 59ms/step - loss: 0.0847 - accuracy: 1.0000 - val_loss: 0.6659 - val_accuracy: 0.6500\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.67536 to 0.66593, saving model to shallow_model3flipped_loss.hdf5\n",
            "Epoch 5/10\n",
            "55/55 [==============================] - 3s 59ms/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.6678 - val_accuracy: 0.6667\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.66593\n",
            "Epoch 6/10\n",
            "55/55 [==============================] - 3s 60ms/step - loss: 0.0494 - accuracy: 1.0000 - val_loss: 0.6690 - val_accuracy: 0.6833\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.66593\n",
            "Epoch 7/10\n",
            "55/55 [==============================] - 3s 60ms/step - loss: 0.0389 - accuracy: 1.0000 - val_loss: 0.6628 - val_accuracy: 0.6833\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.66593 to 0.66277, saving model to shallow_model3flipped_loss.hdf5\n",
            "Epoch 8/10\n",
            "55/55 [==============================] - 3s 60ms/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.6663 - val_accuracy: 0.6833\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.66277\n",
            "Epoch 9/10\n",
            "55/55 [==============================] - 3s 60ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 0.6678 - val_accuracy: 0.6833\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.66277\n",
            "Epoch 10/10\n",
            "55/55 [==============================] - 3s 60ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.6660 - val_accuracy: 0.6833\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.66277\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FFvn9biYOAO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "9653495a-a9f5-464a-a084-1e3f94251772"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grtNEPvSi-A1"
      },
      "source": [
        "         \n",
        "test_label = to_categorical(test_label, num_classes=2)     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2jR6Y1FpfGd"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(shallow_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quant_model = converter.convert()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZzcrX2B-oTU"
      },
      "source": [
        "import pathlib\n",
        "\n",
        "tflite_models_dir = pathlib.Path(\"\")\n",
        "#tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
        "'''\n",
        "# Save the unquantized/float model:\n",
        "tflite_model_file = tflite_models_dir/\"mnist_model.tflite\"\n",
        "tflite_model_file.write_bytes(tflite_model)\n",
        "'''\n",
        "# Save the quantized model:\n",
        "tflite_model_quant_file = tflite_models_dir/\"model_quant.tflite\"\n",
        "tflite_model_quant_file.write_bytes(tflite_quant_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYubxf3s-tEQ"
      },
      "source": [
        "tflite_interpreter = tf.lite.Interpreter('model_quant.tflite')\n",
        "\n",
        "input_details = tflite_interpreter.get_input_details()\n",
        "output_details = tflite_interpreter.get_output_details()\n",
        "\n",
        "\n",
        "#tflite_interpreter.resize_tensor_input(input_details[0]['index'], (60, 22, 15000))\n",
        "#tflite_interpreter.resize_tensor_input(output_details[0]['index'], (60, 2))\n",
        "tflite_interpreter.allocate_tensors()\n",
        "\n",
        "\n",
        "predictions = []\n",
        "for data in test_data:\n",
        "  tflite_interpreter.set_tensor(input_details[0]['index'], [data])\n",
        "\n",
        "  tflite_interpreter.invoke()\n",
        "\n",
        "  tflite_model_predictions = tflite_interpreter.get_tensor(output_details[0]['index'])\n",
        "  print(\"Prediction results shape:\", tflite_model_predictions.shape)\n",
        "  predictions.append(tflite_model_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x84hHaVY-ui0"
      },
      "source": [
        "count = 0\n",
        "for i in range(len(predictions)):\n",
        "  if (predictions[i][0][0] > predictions[i][0][1]) and (test_label[i][0] == 1):\n",
        "    count += 1\n",
        "  elif (predictions[i][0][0] < predictions[i][0][1]) and (test_label[i][1] == 1):\n",
        "    count += 1\n",
        "print(f'total correct predictions = {count}')\n",
        "print(f'accuracy = {count/60}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydfP8-IJ-wf7"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(shallow_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_types = [tf.float16]\n",
        "tflite_quant_model_f = converter.convert()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiQ78xp-Ccm0"
      },
      "source": [
        "import pathlib\n",
        "\n",
        "tflite_models_dir = pathlib.Path(\"\")\n",
        "#tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
        "'''\n",
        "# Save the unquantized/float model:\n",
        "tflite_model_file = tflite_models_dir/\"mnist_model.tflite\"\n",
        "tflite_model_file.write_bytes(tflite_model)\n",
        "'''\n",
        "# Save the quantized model:\n",
        "tflite_model_quant_file = tflite_models_dir/\"model_quant_f.tflite\"\n",
        "tflite_model_quant_file.write_bytes(tflite_quant_model_f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfHmerwXCem0"
      },
      "source": [
        "tflite_interpreter = tf.lite.Interpreter('model_quant_f.tflite')\n",
        "\n",
        "input_details = tflite_interpreter.get_input_details()\n",
        "output_details = tflite_interpreter.get_output_details()\n",
        "\n",
        "\n",
        "#tflite_interpreter.resize_tensor_input(input_details[0]['index'], (60, 22, 15000))\n",
        "#tflite_interpreter.resize_tensor_input(output_details[0]['index'], (60, 2))\n",
        "tflite_interpreter.allocate_tensors()\n",
        "\n",
        "\n",
        "predictions = []\n",
        "for data in test_data:\n",
        "  tflite_interpreter.set_tensor(input_details[0]['index'], [data])\n",
        "\n",
        "  tflite_interpreter.invoke()\n",
        "\n",
        "  tflite_model_predictions = tflite_interpreter.get_tensor(output_details[0]['index'])\n",
        "  print(\"Prediction results shape:\", tflite_model_predictions.shape)\n",
        "  predictions.append(tflite_model_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCxXJtLtChJ5"
      },
      "source": [
        "count = 0\n",
        "for i in range(len(predictions)):\n",
        "  if (predictions[i][0][0] > predictions[i][0][1]) and (test_label[i][0] == 1):\n",
        "    count += 1\n",
        "  elif (predictions[i][0][0] < predictions[i][0][1]) and (test_label[i][1] == 1):\n",
        "    count += 1\n",
        "print(f'total correct predictions = {count}')\n",
        "print(f'accuracy = {count/60}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO9G1ReBfbG8"
      },
      "source": [
        "# Pruning 50 %"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DO8_HchCfcGk",
        "outputId": "3e43ecc5-274c-4b8a-adbc-9f4f0ba921ea"
      },
      "source": [
        "shallow_model.load_weights(\"/content/shallow_model3flipped_loss.hdf5\")\n",
        "\n",
        "\n",
        "!pip install tensorflow_model_optimization\n",
        "is_tfmot = True\n",
        "\n",
        "\n",
        "if not(is_tfmot):\n",
        "  !pip install tensorflow_model_optimization\n",
        "  is_tfmot = True\n",
        "\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Compute end step to finish pruning after 2 epochs.\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "#validation_split = 0.1 # 10% of training set will be used for validation set. \n",
        "\n",
        "num_images = eval_data.shape[0]\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "\n",
        "# Define model for pruning.\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.20,\n",
        "                                                               final_sparsity=0.50,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step,\n",
        "                                                               frequency=5)\n",
        "}\n",
        "\n",
        "model_for_pruning = prune_low_magnitude(shallow_model, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_for_pruning.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_model_optimization in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.15.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (0.1.6)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.19.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 22, 15000)]       0         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d ( (None, 22, 40)            30000042  \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_flatten  (None, 880)               1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense (P (None, 2)                 3524      \n",
            "=================================================================\n",
            "Total params: 30,003,567\n",
            "Trainable params: 15,001,802\n",
            "Non-trainable params: 15,001,765\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXytBS_UfioL",
        "outputId": "13282942-8c3b-4249-80c6-a4eb67f9f885"
      },
      "source": [
        "import tempfile\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "\n",
        "hist = model_for_pruning.fit(eval_data, eval_label, validation_data=(test_data, test_label), epochs=10, batch_size=128, verbose=1, callbacks=callbacks) #epochs #split #"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "14/14 [==============================] - 41s 443ms/step - loss: 1.8013 - accuracy: 0.7606 - val_loss: 2.1342 - val_accuracy: 0.7333\n",
            "Epoch 2/10\n",
            "14/14 [==============================] - 3s 185ms/step - loss: 0.5757 - accuracy: 0.9377 - val_loss: 3.0913 - val_accuracy: 0.7333\n",
            "Epoch 3/10\n",
            "14/14 [==============================] - 3s 185ms/step - loss: 0.0291 - accuracy: 0.9932 - val_loss: 3.0252 - val_accuracy: 0.7500\n",
            "Epoch 4/10\n",
            "14/14 [==============================] - 3s 187ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 2.8163 - val_accuracy: 0.7167\n",
            "Epoch 5/10\n",
            "14/14 [==============================] - 3s 183ms/step - loss: 6.0539e-04 - accuracy: 1.0000 - val_loss: 2.8110 - val_accuracy: 0.7333\n",
            "Epoch 6/10\n",
            "14/14 [==============================] - 3s 184ms/step - loss: 2.7891e-04 - accuracy: 1.0000 - val_loss: 2.8072 - val_accuracy: 0.7333\n",
            "Epoch 7/10\n",
            "14/14 [==============================] - 3s 191ms/step - loss: 2.1088e-04 - accuracy: 1.0000 - val_loss: 2.7716 - val_accuracy: 0.7333\n",
            "Epoch 8/10\n",
            "14/14 [==============================] - 3s 188ms/step - loss: 2.0022e-04 - accuracy: 1.0000 - val_loss: 2.7364 - val_accuracy: 0.7333\n",
            "Epoch 9/10\n",
            "14/14 [==============================] - 3s 187ms/step - loss: 1.8528e-04 - accuracy: 1.0000 - val_loss: 2.6978 - val_accuracy: 0.7333\n",
            "Epoch 10/10\n",
            "14/14 [==============================] - 3s 176ms/step - loss: 1.8552e-04 - accuracy: 1.0000 - val_loss: 2.6872 - val_accuracy: 0.7333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFFPivzGflaG",
        "outputId": "3fbc1122-1cdb-4521-ebba-6ef48e98e79f"
      },
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)\n",
        "\n",
        "\n",
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "_, deep_pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model_for_export, deep_pruned_keras_file, include_optimizer=False)\n",
        "print('Saved pruned Keras model to:', deep_pruned_keras_file)\n",
        "\n",
        "#print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(deep_keras_file)))\n",
        "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(deep_pruned_keras_file)))\n",
        "\n",
        "model_for_export = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved pruned Keras model to: /tmp/tmplwirb7rr.h5\n",
            "Size of gzipped pruned Keras model: 40422684.00 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpMEQ1TLfwBL"
      },
      "source": [
        "# Pruning 60 %"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "As7LUJ0diWeW",
        "outputId": "61d14e7e-3b85-4731-f8ed-e75cbb6ad7e4"
      },
      "source": [
        "shallow_model.load_weights(\"/content/shallow_model3flipped_loss.hdf5\")\n",
        "\n",
        "\n",
        "!pip install tensorflow_model_optimization\n",
        "is_tfmot = True\n",
        "\n",
        "\n",
        "if not(is_tfmot):\n",
        "  !pip install tensorflow_model_optimization\n",
        "  is_tfmot = True\n",
        "\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Compute end step to finish pruning after 2 epochs.\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "#validation_split = 0.1 # 10% of training set will be used for validation set. \n",
        "\n",
        "num_images = eval_data.shape[0]\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "\n",
        "# Define model for pruning.\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.20,\n",
        "                                                               final_sparsity=0.60,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step,\n",
        "                                                               frequency=5)\n",
        "}\n",
        "\n",
        "model_for_pruning = prune_low_magnitude(shallow_model, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_for_pruning.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_model_optimization in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (0.1.6)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.19.5)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.15.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 22, 15000)]       0         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d ( (None, 22, 40)            30000042  \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_flatten  (None, 880)               1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense (P (None, 2)                 3524      \n",
            "=================================================================\n",
            "Total params: 30,003,567\n",
            "Trainable params: 15,001,802\n",
            "Non-trainable params: 15,001,765\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BrRvNXYicQK",
        "outputId": "b2bb66ad-bafb-4d99-9359-08ed8357ca4b"
      },
      "source": [
        "import tempfile\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "\n",
        "hist = model_for_pruning.fit(eval_data, eval_label, validation_data=(test_data, test_label), epochs=10, batch_size=128, verbose=1, callbacks=callbacks) #epochs #split #"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "14/14 [==============================] - 41s 452ms/step - loss: 2.2186 - accuracy: 0.7348 - val_loss: 2.6523 - val_accuracy: 0.7000\n",
            "Epoch 2/10\n",
            "14/14 [==============================] - 3s 193ms/step - loss: 0.5342 - accuracy: 0.9428 - val_loss: 2.6064 - val_accuracy: 0.8000\n",
            "Epoch 3/10\n",
            "14/14 [==============================] - 3s 188ms/step - loss: 0.0532 - accuracy: 0.9901 - val_loss: 2.5122 - val_accuracy: 0.8333\n",
            "Epoch 4/10\n",
            "14/14 [==============================] - 3s 199ms/step - loss: 0.0213 - accuracy: 0.9971 - val_loss: 2.4049 - val_accuracy: 0.8333\n",
            "Epoch 5/10\n",
            "14/14 [==============================] - 3s 179ms/step - loss: 9.4903e-04 - accuracy: 1.0000 - val_loss: 2.3239 - val_accuracy: 0.8167\n",
            "Epoch 6/10\n",
            "14/14 [==============================] - 3s 183ms/step - loss: 5.6132e-04 - accuracy: 1.0000 - val_loss: 2.3081 - val_accuracy: 0.8167\n",
            "Epoch 7/10\n",
            "14/14 [==============================] - 3s 200ms/step - loss: 4.5933e-04 - accuracy: 1.0000 - val_loss: 2.2698 - val_accuracy: 0.8167\n",
            "Epoch 8/10\n",
            "14/14 [==============================] - 3s 196ms/step - loss: 3.7060e-04 - accuracy: 1.0000 - val_loss: 2.2304 - val_accuracy: 0.8167\n",
            "Epoch 9/10\n",
            "14/14 [==============================] - 3s 191ms/step - loss: 3.4665e-04 - accuracy: 1.0000 - val_loss: 2.2170 - val_accuracy: 0.8167\n",
            "Epoch 10/10\n",
            "14/14 [==============================] - 3s 178ms/step - loss: 3.4352e-04 - accuracy: 1.0000 - val_loss: 2.2090 - val_accuracy: 0.8167\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUMWFhCuieeh",
        "outputId": "4a414dbb-26b2-41cf-c2d9-429d091cffc0"
      },
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)\n",
        "\n",
        "\n",
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "_, deep_pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model_for_export, deep_pruned_keras_file, include_optimizer=False)\n",
        "print('Saved pruned Keras model to:', deep_pruned_keras_file)\n",
        "\n",
        "#print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(deep_keras_file)))\n",
        "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(deep_pruned_keras_file)))\n",
        "\n",
        "model_for_export = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved pruned Keras model to: /tmp/tmpgzb95bp0.h5\n",
            "Size of gzipped pruned Keras model: 37586108.00 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfCpEHzjimxt"
      },
      "source": [
        "#Prunning 70%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoVyMixTiskU",
        "outputId": "f97d1397-cbf0-4fa3-fba4-cc2c268ca0d7"
      },
      "source": [
        "shallow_model.load_weights(\"/content/shallow_model3flipped_loss.hdf5\")\n",
        "\n",
        "\n",
        "!pip install tensorflow_model_optimization\n",
        "is_tfmot = True\n",
        "\n",
        "\n",
        "if not(is_tfmot):\n",
        "  !pip install tensorflow_model_optimization\n",
        "  is_tfmot = True\n",
        "\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Compute end step to finish pruning after 2 epochs.\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "#validation_split = 0.1 # 10% of training set will be used for validation set. \n",
        "\n",
        "num_images = eval_data.shape[0]\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "\n",
        "# Define model for pruning.\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.30,\n",
        "                                                               final_sparsity=0.70,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step,\n",
        "                                                               frequency=5)\n",
        "}\n",
        "\n",
        "model_for_pruning = prune_low_magnitude(shallow_model, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_for_pruning.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_model_optimization in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.15.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (0.1.6)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.19.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 22, 15000)]       0         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d ( (None, 22, 40)            30000042  \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_flatten  (None, 880)               1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense (P (None, 2)                 3524      \n",
            "=================================================================\n",
            "Total params: 30,003,567\n",
            "Trainable params: 15,001,802\n",
            "Non-trainable params: 15,001,765\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxoybuaqiwpY",
        "outputId": "7afb048d-3747-43c7-f247-9f8c9e48651c"
      },
      "source": [
        "import tempfile\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "\n",
        "hist = model_for_pruning.fit(eval_data, eval_label, validation_data=(test_data, test_label), epochs=10, batch_size=128, verbose=1, callbacks=callbacks) #epochs #split #"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "14/14 [==============================] - 41s 459ms/step - loss: 1.6063 - accuracy: 0.7532 - val_loss: 5.0479 - val_accuracy: 0.6667\n",
            "Epoch 2/10\n",
            "14/14 [==============================] - 3s 187ms/step - loss: 0.4828 - accuracy: 0.9500 - val_loss: 4.6643 - val_accuracy: 0.6333\n",
            "Epoch 3/10\n",
            "14/14 [==============================] - 3s 196ms/step - loss: 0.0622 - accuracy: 0.9886 - val_loss: 4.2536 - val_accuracy: 0.6833\n",
            "Epoch 4/10\n",
            "14/14 [==============================] - 3s 190ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 4.0990 - val_accuracy: 0.7167\n",
            "Epoch 5/10\n",
            "14/14 [==============================] - 3s 188ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.9654 - val_accuracy: 0.7333\n",
            "Epoch 6/10\n",
            "14/14 [==============================] - 3s 177ms/step - loss: 7.1490e-04 - accuracy: 1.0000 - val_loss: 3.8032 - val_accuracy: 0.7333\n",
            "Epoch 7/10\n",
            "14/14 [==============================] - 3s 191ms/step - loss: 5.5246e-04 - accuracy: 1.0000 - val_loss: 3.7120 - val_accuracy: 0.7333\n",
            "Epoch 8/10\n",
            "14/14 [==============================] - 3s 195ms/step - loss: 5.5044e-04 - accuracy: 1.0000 - val_loss: 3.6715 - val_accuracy: 0.7333\n",
            "Epoch 9/10\n",
            "14/14 [==============================] - 3s 193ms/step - loss: 5.2329e-04 - accuracy: 1.0000 - val_loss: 3.5115 - val_accuracy: 0.7500\n",
            "Epoch 10/10\n",
            "14/14 [==============================] - 3s 185ms/step - loss: 5.0100e-04 - accuracy: 1.0000 - val_loss: 3.4663 - val_accuracy: 0.7500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOBfFqd5iy60",
        "outputId": "0f0dda1b-ad56-46e0-b406-f4d81abfca1b"
      },
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)\n",
        "\n",
        "\n",
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "_, deep_pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model_for_export, deep_pruned_keras_file, include_optimizer=False)\n",
        "print('Saved pruned Keras model to:', deep_pruned_keras_file)\n",
        "\n",
        "#print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(deep_keras_file)))\n",
        "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(deep_pruned_keras_file)))\n",
        "\n",
        "model_for_export = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved pruned Keras model to: /tmp/tmpjj2do8lu.h5\n",
            "Size of gzipped pruned Keras model: 32659064.00 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx3TRm60Z7Hd"
      },
      "source": [
        "# Pruning 80%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pr4yXbv0CpJs",
        "outputId": "98c4e5a2-a34c-4481-93b1-6317645c1565"
      },
      "source": [
        "shallow_model.load_weights(\"/content/shallow_model3flipped_loss.hdf5\")\n",
        "\n",
        "\n",
        "!pip install tensorflow_model_optimization\n",
        "is_tfmot = True\n",
        "\n",
        "\n",
        "if not(is_tfmot):\n",
        "  !pip install tensorflow_model_optimization\n",
        "  is_tfmot = True\n",
        "\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Compute end step to finish pruning after 2 epochs.\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "#validation_split = 0.1 # 10% of training set will be used for validation set. \n",
        "\n",
        "num_images = eval_data.shape[0]\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "\n",
        "# Define model for pruning.\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.30,\n",
        "                                                               final_sparsity=0.80,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step,\n",
        "                                                               frequency=5)\n",
        "}\n",
        "\n",
        "model_for_pruning = prune_low_magnitude(shallow_model, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_for_pruning.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_model_optimization in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.15.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (0.1.6)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.19.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 22, 15000)]       0         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d ( (None, 22, 40)            30000042  \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_flatten  (None, 880)               1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense (P (None, 2)                 3524      \n",
            "=================================================================\n",
            "Total params: 30,003,567\n",
            "Trainable params: 15,001,802\n",
            "Non-trainable params: 15,001,765\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL4XpG3Jd7Av",
        "outputId": "51120ee9-2a36-432e-9796-818c795e0dc0"
      },
      "source": [
        "import tempfile\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "\n",
        "hist = model_for_pruning.fit(eval_data, eval_label, validation_data=(test_data, test_label), epochs=10, batch_size=128, verbose=1, callbacks=callbacks) #epochs #split #"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "14/14 [==============================] - 40s 389ms/step - loss: 1.5743 - accuracy: 0.7511 - val_loss: 3.1712 - val_accuracy: 0.6833\n",
            "Epoch 2/10\n",
            "14/14 [==============================] - 3s 190ms/step - loss: 0.4072 - accuracy: 0.9548 - val_loss: 3.0713 - val_accuracy: 0.6667\n",
            "Epoch 3/10\n",
            "14/14 [==============================] - 3s 190ms/step - loss: 0.0801 - accuracy: 0.9891 - val_loss: 2.9333 - val_accuracy: 0.7500\n",
            "Epoch 4/10\n",
            "14/14 [==============================] - 3s 197ms/step - loss: 0.0122 - accuracy: 0.9990 - val_loss: 2.6711 - val_accuracy: 0.7667\n",
            "Epoch 5/10\n",
            "14/14 [==============================] - 3s 181ms/step - loss: 9.3718e-04 - accuracy: 1.0000 - val_loss: 2.5534 - val_accuracy: 0.7833\n",
            "Epoch 6/10\n",
            "14/14 [==============================] - 3s 180ms/step - loss: 6.5595e-04 - accuracy: 1.0000 - val_loss: 2.4236 - val_accuracy: 0.7667\n",
            "Epoch 7/10\n",
            "14/14 [==============================] - 3s 199ms/step - loss: 9.5514e-04 - accuracy: 1.0000 - val_loss: 2.3527 - val_accuracy: 0.7667\n",
            "Epoch 8/10\n",
            "14/14 [==============================] - 3s 197ms/step - loss: 7.8758e-04 - accuracy: 1.0000 - val_loss: 2.2638 - val_accuracy: 0.7667\n",
            "Epoch 9/10\n",
            "14/14 [==============================] - 3s 195ms/step - loss: 8.6717e-04 - accuracy: 1.0000 - val_loss: 2.1991 - val_accuracy: 0.7667\n",
            "Epoch 10/10\n",
            "14/14 [==============================] - 3s 184ms/step - loss: 7.0499e-04 - accuracy: 1.0000 - val_loss: 2.1389 - val_accuracy: 0.7667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVZpw19heFPU",
        "outputId": "17a1a0b3-3ece-4326-84f6-33ac41be3102"
      },
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)\n",
        "\n",
        "\n",
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "_, deep_pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model_for_export, deep_pruned_keras_file, include_optimizer=False)\n",
        "print('Saved pruned Keras model to:', deep_pruned_keras_file)\n",
        "\n",
        "#print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(deep_keras_file)))\n",
        "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(deep_pruned_keras_file)))\n",
        "\n",
        "model_for_export = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved pruned Keras model to: /tmp/tmpjywxl205.h5\n",
            "Size of gzipped pruned Keras model: 29627197.00 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9CwtCNFpZJg"
      },
      "source": [
        "# Pruning 90%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqNUNr2nel_U"
      },
      "source": [
        "shallow_model.load_weights(\"/content/shallow_model3flipped_loss.hdf5\")\n",
        "\n",
        "\n",
        "!pip install tensorflow_model_optimization\n",
        "is_tfmot = True\n",
        "\n",
        "\n",
        "if not(is_tfmot):\n",
        "  !pip install tensorflow_model_optimization\n",
        "  is_tfmot = True\n",
        "\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Compute end step to finish pruning after 2 epochs.\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "#validation_split = 0.1 # 10% of training set will be used for validation set. \n",
        "\n",
        "num_images = eval_data.shape[0]\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "\n",
        "# Define model for pruning.\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.30,\n",
        "                                                               final_sparsity=0.90,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step,\n",
        "                                                               frequency=5)\n",
        "}\n",
        "\n",
        "model_for_pruning = prune_low_magnitude(shallow_model, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_for_pruning.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRRxbY4rpc93"
      },
      "source": [
        "import tempfile\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "\n",
        "hist = model_for_pruning.fit(eval_data, eval_label, validation_data=(test_data, test_label), epochs=10, batch_size=128, verbose=1, callbacks=callbacks) #epochs #split #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0dn0JqvpfUZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "16422de5-8a12-4fd9-8e44-906a97a133fe"
      },
      "source": [
        "\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)\n",
        "\n",
        "\n",
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "_, deep_pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model_for_export, deep_pruned_keras_file, include_optimizer=False)\n",
        "print('Saved pruned Keras model to:', deep_pruned_keras_file)\n",
        "\n",
        "#print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(deep_keras_file)))\n",
        "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(deep_pruned_keras_file)))\n",
        "\n",
        "model_for_export = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-f127eba5266b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmodel_for_export\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfmot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparsity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip_pruning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_for_pruning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep_pruned_keras_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkstemp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tfmot' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQtSZZp8phPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8c596d2-4914-4741-cdb5-7ccc32741ecc"
      },
      "source": [
        "\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)\n",
        "\n",
        "\n",
        "#model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "#_, deep_pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "#tf.keras.models.save_model(model_for_export, deep_pruned_keras_file, include_optimizer=False)\n",
        "#print('Saved pruned Keras model to:', deep_pruned_keras_file)\n",
        "\n",
        "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(\"/content/shallow_model3flipped_loss.hdf5\")))\n",
        "#print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(deep_pruned_keras_file)))\n",
        "\n",
        "model_for_export = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of gzipped baseline Keras model: 151541380.00 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN7NHTf2nByO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}